TRAINING_STARTED 2025-08-14 13:57:00
STEP 1 EPOCH 0.00
STEP 2 EPOCH 0.00
STEP 3 EPOCH 0.01
STEP 4 EPOCH 0.01
STEP 5 EPOCH 0.01
STEP 6 EPOCH 0.01
STEP 7 EPOCH 0.01
STEP 8 EPOCH 0.01
STEP 9 EPOCH 0.02
STEP 10 EPOCH 0.02
LOG loss=0.594, grad_norm=20.915224075317383, learning_rate=1.153846153846154e-06, epoch=0.017094017094017096
STEP 11 EPOCH 0.02
STEP 12 EPOCH 0.02
STEP 13 EPOCH 0.02
STEP 14 EPOCH 0.02
STEP 15 EPOCH 0.03
STEP 16 EPOCH 0.03
STEP 17 EPOCH 0.03
STEP 18 EPOCH 0.03
STEP 19 EPOCH 0.03
STEP 20 EPOCH 0.03
LOG loss=0.311, grad_norm=2.2343945503234863, learning_rate=2.435897435897436e-06, epoch=0.03418803418803419
STEP 21 EPOCH 0.04
STEP 22 EPOCH 0.04
STEP 23 EPOCH 0.04
STEP 24 EPOCH 0.04
STEP 25 EPOCH 0.04
STEP 26 EPOCH 0.04
STEP 27 EPOCH 0.05
STEP 28 EPOCH 0.05
STEP 29 EPOCH 0.05
STEP 30 EPOCH 0.05
LOG loss=0.3469, grad_norm=20.267366409301758, learning_rate=3.717948717948718e-06, epoch=0.05128205128205128
STEP 31 EPOCH 0.05
STEP 32 EPOCH 0.05
STEP 33 EPOCH 0.06
STEP 34 EPOCH 0.06
STEP 35 EPOCH 0.06
STEP 36 EPOCH 0.06
STEP 37 EPOCH 0.06
STEP 38 EPOCH 0.06
STEP 39 EPOCH 0.07
STEP 40 EPOCH 0.07
LOG loss=0.2531, grad_norm=5.591670989990234, learning_rate=4.9999999999999996e-06, epoch=0.06837606837606838
STEP 41 EPOCH 0.07
STEP 42 EPOCH 0.07
STEP 43 EPOCH 0.07
STEP 44 EPOCH 0.08
STEP 45 EPOCH 0.08
STEP 46 EPOCH 0.08
STEP 47 EPOCH 0.08
STEP 48 EPOCH 0.08
STEP 49 EPOCH 0.08
STEP 50 EPOCH 0.09
LOG loss=0.1737, grad_norm=0.8279908895492554, learning_rate=6.282051282051282e-06, epoch=0.08547008547008547
STEP 51 EPOCH 0.09
STEP 52 EPOCH 0.09
STEP 53 EPOCH 0.09
STEP 54 EPOCH 0.09
STEP 55 EPOCH 0.09
STEP 56 EPOCH 0.10
STEP 57 EPOCH 0.10
STEP 58 EPOCH 0.10
STEP 59 EPOCH 0.10
STEP 60 EPOCH 0.10
LOG loss=0.1347, grad_norm=0.19788764417171478, learning_rate=7.564102564102564e-06, epoch=0.10256410256410256
STEP 61 EPOCH 0.10
STEP 62 EPOCH 0.11
STEP 63 EPOCH 0.11
STEP 64 EPOCH 0.11
STEP 65 EPOCH 0.11
STEP 66 EPOCH 0.11
STEP 67 EPOCH 0.11
STEP 68 EPOCH 0.12
STEP 69 EPOCH 0.12
STEP 70 EPOCH 0.12
LOG loss=0.2502, grad_norm=0.2779173254966736, learning_rate=8.846153846153847e-06, epoch=0.11965811965811966
STEP 71 EPOCH 0.12
STEP 72 EPOCH 0.12
STEP 73 EPOCH 0.12
STEP 74 EPOCH 0.13
STEP 75 EPOCH 0.13
STEP 76 EPOCH 0.13
STEP 77 EPOCH 0.13
STEP 78 EPOCH 0.13
STEP 79 EPOCH 0.14
STEP 80 EPOCH 0.14
LOG loss=0.1067, grad_norm=15.819238662719727, learning_rate=1.012820512820513e-05, epoch=0.13675213675213677
STEP 81 EPOCH 0.14
STEP 82 EPOCH 0.14
STEP 83 EPOCH 0.14
STEP 84 EPOCH 0.14
STEP 85 EPOCH 0.15
STEP 86 EPOCH 0.15
STEP 87 EPOCH 0.15
STEP 88 EPOCH 0.15
STEP 89 EPOCH 0.15
STEP 90 EPOCH 0.15
LOG loss=0.1994, grad_norm=0.08350582420825958, learning_rate=1.141025641025641e-05, epoch=0.15384615384615385
STEP 91 EPOCH 0.16
STEP 92 EPOCH 0.16
STEP 93 EPOCH 0.16
STEP 94 EPOCH 0.16
STEP 95 EPOCH 0.16
STEP 96 EPOCH 0.16
STEP 97 EPOCH 0.17
STEP 98 EPOCH 0.17
STEP 99 EPOCH 0.17
STEP 100 EPOCH 0.17
LOG loss=0.0519, grad_norm=0.6722465753555298, learning_rate=1.2692307692307693e-05, epoch=0.17094017094017094
STEP 101 EPOCH 0.17
STEP 102 EPOCH 0.17
STEP 103 EPOCH 0.18
STEP 104 EPOCH 0.18
STEP 105 EPOCH 0.18
STEP 106 EPOCH 0.18
STEP 107 EPOCH 0.18
STEP 108 EPOCH 0.18
STEP 109 EPOCH 0.19
STEP 110 EPOCH 0.19
LOG loss=0.0713, grad_norm=1.661204218864441, learning_rate=1.3974358974358975e-05, epoch=0.18803418803418803
STEP 111 EPOCH 0.19
STEP 112 EPOCH 0.19
STEP 113 EPOCH 0.19
STEP 114 EPOCH 0.19
STEP 115 EPOCH 0.20
STEP 116 EPOCH 0.20
STEP 117 EPOCH 0.20
STEP 118 EPOCH 0.20
STEP 119 EPOCH 0.20
STEP 120 EPOCH 0.21
LOG loss=0.0659, grad_norm=0.08513589203357697, learning_rate=1.5256410256410255e-05, epoch=0.20512820512820512
STEP 121 EPOCH 0.21
STEP 122 EPOCH 0.21
STEP 123 EPOCH 0.21
STEP 124 EPOCH 0.21
STEP 125 EPOCH 0.21
STEP 126 EPOCH 0.22
STEP 127 EPOCH 0.22
STEP 128 EPOCH 0.22
STEP 129 EPOCH 0.22
STEP 130 EPOCH 0.22
LOG loss=0.0552, grad_norm=15.804015159606934, learning_rate=1.653846153846154e-05, epoch=0.2222222222222222
STEP 131 EPOCH 0.22
STEP 132 EPOCH 0.23
STEP 133 EPOCH 0.23
STEP 134 EPOCH 0.23
STEP 135 EPOCH 0.23
STEP 136 EPOCH 0.23
STEP 137 EPOCH 0.23
STEP 138 EPOCH 0.24
STEP 139 EPOCH 0.24
STEP 140 EPOCH 0.24
LOG loss=0.0912, grad_norm=3.326526165008545, learning_rate=1.782051282051282e-05, epoch=0.23931623931623933
STEP 141 EPOCH 0.24
STEP 142 EPOCH 0.24
STEP 143 EPOCH 0.24
STEP 144 EPOCH 0.25
STEP 145 EPOCH 0.25
STEP 146 EPOCH 0.25
STEP 147 EPOCH 0.25
STEP 148 EPOCH 0.25
STEP 149 EPOCH 0.25
STEP 150 EPOCH 0.26
LOG loss=0.0425, grad_norm=0.08109837025403976, learning_rate=1.9102564102564103e-05, epoch=0.2564102564102564
STEP 151 EPOCH 0.26
STEP 152 EPOCH 0.26
STEP 153 EPOCH 0.26
STEP 154 EPOCH 0.26
STEP 155 EPOCH 0.26
STEP 156 EPOCH 0.27
STEP 157 EPOCH 0.27
STEP 158 EPOCH 0.27
STEP 159 EPOCH 0.27
STEP 160 EPOCH 0.27
LOG loss=0.1517, grad_norm=51.60313415527344, learning_rate=2.0384615384615387e-05, epoch=0.27350427350427353
STEP 161 EPOCH 0.28
STEP 162 EPOCH 0.28
STEP 163 EPOCH 0.28
STEP 164 EPOCH 0.28
STEP 165 EPOCH 0.28
STEP 166 EPOCH 0.28
STEP 167 EPOCH 0.29
STEP 168 EPOCH 0.29
STEP 169 EPOCH 0.29
STEP 170 EPOCH 0.29
LOG loss=0.0247, grad_norm=0.5918771624565125, learning_rate=2.1666666666666667e-05, epoch=0.2905982905982906
STEP 171 EPOCH 0.29
STEP 172 EPOCH 0.29
STEP 173 EPOCH 0.30
STEP 174 EPOCH 0.30
STEP 175 EPOCH 0.30
STEP 176 EPOCH 0.30
STEP 177 EPOCH 0.30
STEP 178 EPOCH 0.30
STEP 179 EPOCH 0.31
STEP 180 EPOCH 0.31
LOG loss=0.0635, grad_norm=12.559840202331543, learning_rate=2.2948717948717947e-05, epoch=0.3076923076923077
STEP 181 EPOCH 0.31
STEP 182 EPOCH 0.31
STEP 183 EPOCH 0.31
STEP 184 EPOCH 0.31
STEP 185 EPOCH 0.32
STEP 186 EPOCH 0.32
STEP 187 EPOCH 0.32
STEP 188 EPOCH 0.32
STEP 189 EPOCH 0.32
STEP 190 EPOCH 0.32
LOG loss=0.2205, grad_norm=78.58584594726562, learning_rate=2.423076923076923e-05, epoch=0.3247863247863248
STEP 191 EPOCH 0.33
STEP 192 EPOCH 0.33
STEP 193 EPOCH 0.33
STEP 194 EPOCH 0.33
STEP 195 EPOCH 0.33
STEP 196 EPOCH 0.34
STEP 197 EPOCH 0.34
STEP 198 EPOCH 0.34
STEP 199 EPOCH 0.34
STEP 200 EPOCH 0.34
LOG loss=0.1757, grad_norm=0.10610391199588776, learning_rate=2.551282051282051e-05, epoch=0.3418803418803419
STEP 201 EPOCH 0.34
STEP 202 EPOCH 0.35
STEP 203 EPOCH 0.35
STEP 204 EPOCH 0.35
STEP 205 EPOCH 0.35
STEP 206 EPOCH 0.35
STEP 207 EPOCH 0.35
STEP 208 EPOCH 0.36
STEP 209 EPOCH 0.36
STEP 210 EPOCH 0.36
LOG loss=0.1178, grad_norm=0.40707701444625854, learning_rate=2.67948717948718e-05, epoch=0.358974358974359
STEP 211 EPOCH 0.36
STEP 212 EPOCH 0.36
STEP 213 EPOCH 0.36
STEP 214 EPOCH 0.37
STEP 215 EPOCH 0.37
STEP 216 EPOCH 0.37
STEP 217 EPOCH 0.37
STEP 218 EPOCH 0.37
STEP 219 EPOCH 0.37
STEP 220 EPOCH 0.38
LOG loss=0.0515, grad_norm=2.0894503593444824, learning_rate=2.807692307692308e-05, epoch=0.37606837606837606
STEP 221 EPOCH 0.38
STEP 222 EPOCH 0.38
STEP 223 EPOCH 0.38
STEP 224 EPOCH 0.38
STEP 225 EPOCH 0.38
STEP 226 EPOCH 0.39
STEP 227 EPOCH 0.39
STEP 228 EPOCH 0.39
STEP 229 EPOCH 0.39
STEP 230 EPOCH 0.39
LOG loss=0.0086, grad_norm=2.229086399078369, learning_rate=2.935897435897436e-05, epoch=0.39316239316239315
STEP 231 EPOCH 0.39
STEP 232 EPOCH 0.40
STEP 233 EPOCH 0.40
STEP 234 EPOCH 0.40
STEP 235 EPOCH 0.40
STEP 236 EPOCH 0.40
STEP 237 EPOCH 0.41
STEP 238 EPOCH 0.41
STEP 239 EPOCH 0.41
STEP 240 EPOCH 0.41
LOG loss=0.0836, grad_norm=11.171867370605469, learning_rate=2.992877492877493e-05, epoch=0.41025641025641024
STEP 241 EPOCH 0.41
STEP 242 EPOCH 0.41
STEP 243 EPOCH 0.42
STEP 244 EPOCH 0.42
STEP 245 EPOCH 0.42
STEP 246 EPOCH 0.42
STEP 247 EPOCH 0.42
STEP 248 EPOCH 0.42
STEP 249 EPOCH 0.43
STEP 250 EPOCH 0.43
LOG loss=0.0094, grad_norm=1.2787805795669556, learning_rate=2.9786324786324787e-05, epoch=0.42735042735042733
STEP 251 EPOCH 0.43
STEP 252 EPOCH 0.43
STEP 253 EPOCH 0.43
STEP 254 EPOCH 0.43
STEP 255 EPOCH 0.44
STEP 256 EPOCH 0.44
STEP 257 EPOCH 0.44
STEP 258 EPOCH 0.44
STEP 259 EPOCH 0.44
STEP 260 EPOCH 0.44
LOG loss=0.0267, grad_norm=0.004148065112531185, learning_rate=2.9643874643874644e-05, epoch=0.4444444444444444
STEP 261 EPOCH 0.45
STEP 262 EPOCH 0.45
STEP 263 EPOCH 0.45
STEP 264 EPOCH 0.45
STEP 265 EPOCH 0.45
STEP 266 EPOCH 0.45
STEP 267 EPOCH 0.46
STEP 268 EPOCH 0.46
STEP 269 EPOCH 0.46
STEP 270 EPOCH 0.46
LOG loss=0.0268, grad_norm=27.23188591003418, learning_rate=2.95014245014245e-05, epoch=0.46153846153846156
STEP 271 EPOCH 0.46
STEP 272 EPOCH 0.46
STEP 273 EPOCH 0.47
STEP 274 EPOCH 0.47
STEP 275 EPOCH 0.47
STEP 276 EPOCH 0.47
STEP 277 EPOCH 0.47
STEP 278 EPOCH 0.48
STEP 279 EPOCH 0.48
STEP 280 EPOCH 0.48
LOG loss=0.0307, grad_norm=7.03140115737915, learning_rate=2.935897435897436e-05, epoch=0.47863247863247865
STEP 281 EPOCH 0.48
STEP 282 EPOCH 0.48
STEP 283 EPOCH 0.48
STEP 284 EPOCH 0.49
STEP 285 EPOCH 0.49
STEP 286 EPOCH 0.49
STEP 287 EPOCH 0.49
STEP 288 EPOCH 0.49
STEP 289 EPOCH 0.49
STEP 290 EPOCH 0.50
LOG loss=0.0436, grad_norm=8.5167818069458, learning_rate=2.9216524216524216e-05, epoch=0.49572649572649574
STEP 291 EPOCH 0.50
STEP 292 EPOCH 0.50
STEP 293 EPOCH 0.50
STEP 294 EPOCH 0.50
STEP 295 EPOCH 0.50
STEP 296 EPOCH 0.51
STEP 297 EPOCH 0.51
STEP 298 EPOCH 0.51
STEP 299 EPOCH 0.51
STEP 300 EPOCH 0.51
LOG loss=0.1066, grad_norm=13.823025703430176, learning_rate=2.9074074074074074e-05, epoch=0.5128205128205128
STEP 301 EPOCH 0.51
STEP 302 EPOCH 0.52
STEP 303 EPOCH 0.52
STEP 304 EPOCH 0.52
STEP 305 EPOCH 0.52
STEP 306 EPOCH 0.52
STEP 307 EPOCH 0.52
STEP 308 EPOCH 0.53
STEP 309 EPOCH 0.53
STEP 310 EPOCH 0.53
LOG loss=0.1083, grad_norm=9.709237098693848, learning_rate=2.893162393162393e-05, epoch=0.5299145299145299
STEP 311 EPOCH 0.53
STEP 312 EPOCH 0.53
STEP 313 EPOCH 0.54
STEP 314 EPOCH 0.54
STEP 315 EPOCH 0.54
STEP 316 EPOCH 0.54
STEP 317 EPOCH 0.54
STEP 318 EPOCH 0.54
STEP 319 EPOCH 0.55
STEP 320 EPOCH 0.55
LOG loss=0.0561, grad_norm=0.11408944427967072, learning_rate=2.878917378917379e-05, epoch=0.5470085470085471
STEP 321 EPOCH 0.55
STEP 322 EPOCH 0.55
STEP 323 EPOCH 0.55
STEP 324 EPOCH 0.55
STEP 325 EPOCH 0.56
STEP 326 EPOCH 0.56
STEP 327 EPOCH 0.56
STEP 328 EPOCH 0.56
STEP 329 EPOCH 0.56
STEP 330 EPOCH 0.56
LOG loss=0.0286, grad_norm=0.41731083393096924, learning_rate=2.8646723646723646e-05, epoch=0.5641025641025641
STEP 331 EPOCH 0.57
STEP 332 EPOCH 0.57
STEP 333 EPOCH 0.57
STEP 334 EPOCH 0.57
STEP 335 EPOCH 0.57
STEP 336 EPOCH 0.57
STEP 337 EPOCH 0.58
STEP 338 EPOCH 0.58
STEP 339 EPOCH 0.58
STEP 340 EPOCH 0.58
LOG loss=0.0347, grad_norm=0.7893703579902649, learning_rate=2.8504273504273503e-05, epoch=0.5811965811965812
STEP 341 EPOCH 0.58
STEP 342 EPOCH 0.58
STEP 343 EPOCH 0.59
STEP 344 EPOCH 0.59
STEP 345 EPOCH 0.59
STEP 346 EPOCH 0.59
STEP 347 EPOCH 0.59
STEP 348 EPOCH 0.59
STEP 349 EPOCH 0.60
STEP 350 EPOCH 0.60
LOG loss=0.0617, grad_norm=0.07437670975923538, learning_rate=2.8361823361823364e-05, epoch=0.5982905982905983
STEP 351 EPOCH 0.60
STEP 352 EPOCH 0.60
STEP 353 EPOCH 0.60
STEP 354 EPOCH 0.61
STEP 355 EPOCH 0.61
STEP 356 EPOCH 0.61
STEP 357 EPOCH 0.61
STEP 358 EPOCH 0.61
STEP 359 EPOCH 0.61
STEP 360 EPOCH 0.62
LOG loss=0.0137, grad_norm=2.544589042663574, learning_rate=2.821937321937322e-05, epoch=0.6153846153846154
STEP 361 EPOCH 0.62
STEP 362 EPOCH 0.62
STEP 363 EPOCH 0.62
STEP 364 EPOCH 0.62
STEP 365 EPOCH 0.62
STEP 366 EPOCH 0.63
STEP 367 EPOCH 0.63
STEP 368 EPOCH 0.63
STEP 369 EPOCH 0.63
STEP 370 EPOCH 0.63
LOG loss=0.1013, grad_norm=2.5112786293029785, learning_rate=2.807692307692308e-05, epoch=0.6324786324786325
STEP 371 EPOCH 0.63
STEP 372 EPOCH 0.64
STEP 373 EPOCH 0.64
STEP 374 EPOCH 0.64
STEP 375 EPOCH 0.64
STEP 376 EPOCH 0.64
STEP 377 EPOCH 0.64
STEP 378 EPOCH 0.65
STEP 379 EPOCH 0.65
STEP 380 EPOCH 0.65
LOG loss=0.1179, grad_norm=8.261824607849121, learning_rate=2.7934472934472936e-05, epoch=0.6495726495726496
STEP 381 EPOCH 0.65
STEP 382 EPOCH 0.65
STEP 383 EPOCH 0.65
STEP 384 EPOCH 0.66
STEP 385 EPOCH 0.66
STEP 386 EPOCH 0.66
STEP 387 EPOCH 0.66
STEP 388 EPOCH 0.66
STEP 389 EPOCH 0.66
STEP 390 EPOCH 0.67
LOG loss=0.2196, grad_norm=67.50109100341797, learning_rate=2.7792022792022793e-05, epoch=0.6666666666666666
STEP 391 EPOCH 0.67
STEP 392 EPOCH 0.67
STEP 393 EPOCH 0.67
STEP 394 EPOCH 0.67
STEP 395 EPOCH 0.68
STEP 396 EPOCH 0.68
STEP 397 EPOCH 0.68
STEP 398 EPOCH 0.68
STEP 399 EPOCH 0.68
STEP 400 EPOCH 0.68
LOG loss=0.292, grad_norm=0.03361804038286209, learning_rate=2.764957264957265e-05, epoch=0.6837606837606838
STEP 401 EPOCH 0.69
STEP 402 EPOCH 0.69
STEP 403 EPOCH 0.69
STEP 404 EPOCH 0.69
STEP 405 EPOCH 0.69
STEP 406 EPOCH 0.69
STEP 407 EPOCH 0.70
STEP 408 EPOCH 0.70
STEP 409 EPOCH 0.70
STEP 410 EPOCH 0.70
LOG loss=0.0391, grad_norm=4.3909454345703125, learning_rate=2.7507122507122508e-05, epoch=0.7008547008547008
STEP 411 EPOCH 0.70
STEP 412 EPOCH 0.70
STEP 413 EPOCH 0.71
STEP 414 EPOCH 0.71
STEP 415 EPOCH 0.71
STEP 416 EPOCH 0.71
STEP 417 EPOCH 0.71
STEP 418 EPOCH 0.71
STEP 419 EPOCH 0.72
STEP 420 EPOCH 0.72
LOG loss=0.0622, grad_norm=0.08630833774805069, learning_rate=2.7364672364672365e-05, epoch=0.717948717948718
STEP 421 EPOCH 0.72
STEP 422 EPOCH 0.72
STEP 423 EPOCH 0.72
STEP 424 EPOCH 0.72
STEP 425 EPOCH 0.73
STEP 426 EPOCH 0.73
STEP 427 EPOCH 0.73
STEP 428 EPOCH 0.73
STEP 429 EPOCH 0.73
STEP 430 EPOCH 0.74
LOG loss=0.0324, grad_norm=0.03527950122952461, learning_rate=2.7222222222222223e-05, epoch=0.7350427350427351
STEP 431 EPOCH 0.74
STEP 432 EPOCH 0.74
STEP 433 EPOCH 0.74
STEP 434 EPOCH 0.74
STEP 435 EPOCH 0.74
STEP 436 EPOCH 0.75
STEP 437 EPOCH 0.75
STEP 438 EPOCH 0.75
STEP 439 EPOCH 0.75
STEP 440 EPOCH 0.75
LOG loss=0.1587, grad_norm=1.186107873916626, learning_rate=2.707977207977208e-05, epoch=0.7521367521367521
STEP 441 EPOCH 0.75
STEP 442 EPOCH 0.76
STEP 443 EPOCH 0.76
STEP 444 EPOCH 0.76
STEP 445 EPOCH 0.76
STEP 446 EPOCH 0.76
STEP 447 EPOCH 0.76
STEP 448 EPOCH 0.77
STEP 449 EPOCH 0.77
STEP 450 EPOCH 0.77
LOG loss=0.0406, grad_norm=3.626347541809082, learning_rate=2.6937321937321938e-05, epoch=0.7692307692307693
STEP 451 EPOCH 0.77
STEP 452 EPOCH 0.77
STEP 453 EPOCH 0.77
STEP 454 EPOCH 0.78
STEP 455 EPOCH 0.78
STEP 456 EPOCH 0.78
STEP 457 EPOCH 0.78
STEP 458 EPOCH 0.78
STEP 459 EPOCH 0.78
STEP 460 EPOCH 0.79
LOG loss=0.1325, grad_norm=17.568687438964844, learning_rate=2.67948717948718e-05, epoch=0.7863247863247863
STEP 461 EPOCH 0.79
STEP 462 EPOCH 0.79
STEP 463 EPOCH 0.79
STEP 464 EPOCH 0.79
STEP 465 EPOCH 0.79
STEP 466 EPOCH 0.80
STEP 467 EPOCH 0.80
STEP 468 EPOCH 0.80
STEP 469 EPOCH 0.80
STEP 470 EPOCH 0.80
LOG loss=0.2364, grad_norm=4.530449390411377, learning_rate=2.6652421652421656e-05, epoch=0.8034188034188035
STEP 471 EPOCH 0.81
STEP 472 EPOCH 0.81
STEP 473 EPOCH 0.81
STEP 474 EPOCH 0.81
STEP 475 EPOCH 0.81
STEP 476 EPOCH 0.81
STEP 477 EPOCH 0.82
STEP 478 EPOCH 0.82
STEP 479 EPOCH 0.82
STEP 480 EPOCH 0.82
LOG loss=0.0717, grad_norm=0.04585153982043266, learning_rate=2.650997150997151e-05, epoch=0.8205128205128205
STEP 481 EPOCH 0.82
STEP 482 EPOCH 0.82
STEP 483 EPOCH 0.83
STEP 484 EPOCH 0.83
STEP 485 EPOCH 0.83
STEP 486 EPOCH 0.83
STEP 487 EPOCH 0.83
STEP 488 EPOCH 0.83
STEP 489 EPOCH 0.84
STEP 490 EPOCH 0.84
LOG loss=0.1287, grad_norm=152.63406372070312, learning_rate=2.6367521367521367e-05, epoch=0.8376068376068376
STEP 491 EPOCH 0.84
STEP 492 EPOCH 0.84
STEP 493 EPOCH 0.84
STEP 494 EPOCH 0.84
STEP 495 EPOCH 0.85
STEP 496 EPOCH 0.85
STEP 497 EPOCH 0.85
STEP 498 EPOCH 0.85
STEP 499 EPOCH 0.85
STEP 500 EPOCH 0.85
LOG loss=0.1602, grad_norm=0.007708891294896603, learning_rate=2.6225071225071224e-05, epoch=0.8547008547008547
STEP 501 EPOCH 0.86
STEP 502 EPOCH 0.86
STEP 503 EPOCH 0.86
STEP 504 EPOCH 0.86
STEP 505 EPOCH 0.86
STEP 506 EPOCH 0.86
STEP 507 EPOCH 0.87
STEP 508 EPOCH 0.87
STEP 509 EPOCH 0.87
STEP 510 EPOCH 0.87
LOG loss=0.3718, grad_norm=0.009352421388030052, learning_rate=2.6082621082621082e-05, epoch=0.8717948717948718
STEP 511 EPOCH 0.87
STEP 512 EPOCH 0.88
STEP 513 EPOCH 0.88
STEP 514 EPOCH 0.88
STEP 515 EPOCH 0.88
STEP 516 EPOCH 0.88
STEP 517 EPOCH 0.88
STEP 518 EPOCH 0.89
STEP 519 EPOCH 0.89
STEP 520 EPOCH 0.89
LOG loss=0.0218, grad_norm=16.396787643432617, learning_rate=2.594017094017094e-05, epoch=0.8888888888888888
STEP 521 EPOCH 0.89
STEP 522 EPOCH 0.89
STEP 523 EPOCH 0.89
STEP 524 EPOCH 0.90
STEP 525 EPOCH 0.90
STEP 526 EPOCH 0.90
STEP 527 EPOCH 0.90
STEP 528 EPOCH 0.90
STEP 529 EPOCH 0.90
STEP 530 EPOCH 0.91
LOG loss=0.093, grad_norm=0.013986466452479362, learning_rate=2.5797720797720797e-05, epoch=0.905982905982906
STEP 531 EPOCH 0.91
STEP 532 EPOCH 0.91
STEP 533 EPOCH 0.91
STEP 534 EPOCH 0.91
STEP 535 EPOCH 0.91
STEP 536 EPOCH 0.92
STEP 537 EPOCH 0.92
STEP 538 EPOCH 0.92
STEP 539 EPOCH 0.92
STEP 540 EPOCH 0.92
LOG loss=0.0115, grad_norm=12.443977355957031, learning_rate=2.5655270655270654e-05, epoch=0.9230769230769231
STEP 541 EPOCH 0.92
STEP 542 EPOCH 0.93
STEP 543 EPOCH 0.93
STEP 544 EPOCH 0.93
STEP 545 EPOCH 0.93
STEP 546 EPOCH 0.93
STEP 547 EPOCH 0.94
STEP 548 EPOCH 0.94
STEP 549 EPOCH 0.94
STEP 550 EPOCH 0.94
LOG loss=0.2387, grad_norm=45.10161209106445, learning_rate=2.551282051282051e-05, epoch=0.9401709401709402
STEP 551 EPOCH 0.94
STEP 552 EPOCH 0.94
STEP 553 EPOCH 0.95
STEP 554 EPOCH 0.95
STEP 555 EPOCH 0.95
STEP 556 EPOCH 0.95
STEP 557 EPOCH 0.95
STEP 558 EPOCH 0.95
STEP 559 EPOCH 0.96
STEP 560 EPOCH 0.96
LOG loss=0.1224, grad_norm=4.482247352600098, learning_rate=2.5370370370370372e-05, epoch=0.9572649572649573
STEP 561 EPOCH 0.96
STEP 562 EPOCH 0.96
STEP 563 EPOCH 0.96
STEP 564 EPOCH 0.96
STEP 565 EPOCH 0.97
STEP 566 EPOCH 0.97
STEP 567 EPOCH 0.97
STEP 568 EPOCH 0.97
STEP 569 EPOCH 0.97
STEP 570 EPOCH 0.97
LOG loss=0.2029, grad_norm=0.09155351668596268, learning_rate=2.522792022792023e-05, epoch=0.9743589743589743
STEP 571 EPOCH 0.98
STEP 572 EPOCH 0.98
STEP 573 EPOCH 0.98
STEP 574 EPOCH 0.98
STEP 575 EPOCH 0.98
STEP 576 EPOCH 0.98
STEP 577 EPOCH 0.99
STEP 578 EPOCH 0.99
STEP 579 EPOCH 0.99
STEP 580 EPOCH 0.99
LOG loss=0.0748, grad_norm=0.01712423376739025, learning_rate=2.5085470085470087e-05, epoch=0.9914529914529915
STEP 581 EPOCH 0.99
STEP 582 EPOCH 0.99
STEP 583 EPOCH 1.00
STEP 584 EPOCH 1.00
STEP 585 EPOCH 1.00
STEP 586 EPOCH 1.00
STEP 587 EPOCH 1.00
STEP 588 EPOCH 1.01
STEP 589 EPOCH 1.01
STEP 590 EPOCH 1.01
LOG loss=0.2464, grad_norm=6.3857879638671875, learning_rate=2.4943019943019944e-05, epoch=1.0085470085470085
STEP 591 EPOCH 1.01
STEP 592 EPOCH 1.01
STEP 593 EPOCH 1.01
STEP 594 EPOCH 1.02
STEP 595 EPOCH 1.02
STEP 596 EPOCH 1.02
STEP 597 EPOCH 1.02
STEP 598 EPOCH 1.02
STEP 599 EPOCH 1.02
STEP 600 EPOCH 1.03
LOG loss=0.0151, grad_norm=0.8999098539352417, learning_rate=2.48005698005698e-05, epoch=1.0256410256410255
STEP 601 EPOCH 1.03
STEP 602 EPOCH 1.03
STEP 603 EPOCH 1.03
STEP 604 EPOCH 1.03
STEP 605 EPOCH 1.03
STEP 606 EPOCH 1.04
STEP 607 EPOCH 1.04
STEP 608 EPOCH 1.04
STEP 609 EPOCH 1.04
STEP 610 EPOCH 1.04
LOG loss=0.1653, grad_norm=29.309640884399414, learning_rate=2.465811965811966e-05, epoch=1.0427350427350428
STEP 611 EPOCH 1.04
STEP 612 EPOCH 1.05
STEP 613 EPOCH 1.05
STEP 614 EPOCH 1.05
STEP 615 EPOCH 1.05
STEP 616 EPOCH 1.05
STEP 617 EPOCH 1.05
STEP 618 EPOCH 1.06
STEP 619 EPOCH 1.06
STEP 620 EPOCH 1.06
LOG loss=0.3264, grad_norm=0.028529349714517593, learning_rate=2.4515669515669516e-05, epoch=1.0598290598290598
STEP 621 EPOCH 1.06
STEP 622 EPOCH 1.06
STEP 623 EPOCH 1.06
STEP 624 EPOCH 1.07
STEP 625 EPOCH 1.07
STEP 626 EPOCH 1.07
STEP 627 EPOCH 1.07
STEP 628 EPOCH 1.07
STEP 629 EPOCH 1.08
STEP 630 EPOCH 1.08
LOG loss=0.3281, grad_norm=0.06257454305887222, learning_rate=2.4373219373219374e-05, epoch=1.0769230769230769
STEP 631 EPOCH 1.08
STEP 632 EPOCH 1.08
STEP 633 EPOCH 1.08
STEP 634 EPOCH 1.08
STEP 635 EPOCH 1.09
STEP 636 EPOCH 1.09
STEP 637 EPOCH 1.09
STEP 638 EPOCH 1.09
STEP 639 EPOCH 1.09
STEP 640 EPOCH 1.09
LOG loss=0.1097, grad_norm=2.432035446166992, learning_rate=2.423076923076923e-05, epoch=1.0940170940170941
STEP 641 EPOCH 1.10
STEP 642 EPOCH 1.10
STEP 643 EPOCH 1.10
STEP 644 EPOCH 1.10
STEP 645 EPOCH 1.10
STEP 646 EPOCH 1.10
STEP 647 EPOCH 1.11
STEP 648 EPOCH 1.11
STEP 649 EPOCH 1.11
STEP 650 EPOCH 1.11
LOG loss=0.1386, grad_norm=36.35777282714844, learning_rate=2.408831908831909e-05, epoch=1.1111111111111112
STEP 651 EPOCH 1.11
STEP 652 EPOCH 1.11
STEP 653 EPOCH 1.12
STEP 654 EPOCH 1.12
STEP 655 EPOCH 1.12
STEP 656 EPOCH 1.12
STEP 657 EPOCH 1.12
STEP 658 EPOCH 1.12
STEP 659 EPOCH 1.13
STEP 660 EPOCH 1.13
LOG loss=0.014, grad_norm=11.24629020690918, learning_rate=2.3945868945868946e-05, epoch=1.1282051282051282
STEP 661 EPOCH 1.13
STEP 662 EPOCH 1.13
STEP 663 EPOCH 1.13
STEP 664 EPOCH 1.14
STEP 665 EPOCH 1.14
STEP 666 EPOCH 1.14
STEP 667 EPOCH 1.14
STEP 668 EPOCH 1.14
STEP 669 EPOCH 1.14
STEP 670 EPOCH 1.15
LOG loss=0.4214, grad_norm=0.6630836129188538, learning_rate=2.3803418803418806e-05, epoch=1.1452991452991452
STEP 671 EPOCH 1.15
STEP 672 EPOCH 1.15
STEP 673 EPOCH 1.15
STEP 674 EPOCH 1.15
STEP 675 EPOCH 1.15
STEP 676 EPOCH 1.16
STEP 677 EPOCH 1.16
STEP 678 EPOCH 1.16
STEP 679 EPOCH 1.16
STEP 680 EPOCH 1.16
LOG loss=0.1175, grad_norm=1.0189111232757568, learning_rate=2.3660968660968664e-05, epoch=1.1623931623931625
STEP 681 EPOCH 1.16
STEP 682 EPOCH 1.17
STEP 683 EPOCH 1.17
STEP 684 EPOCH 1.17
STEP 685 EPOCH 1.17
STEP 686 EPOCH 1.17
STEP 687 EPOCH 1.17
STEP 688 EPOCH 1.18
STEP 689 EPOCH 1.18
STEP 690 EPOCH 1.18
LOG loss=0.1241, grad_norm=8.405131340026855, learning_rate=2.351851851851852e-05, epoch=1.1794871794871795
STEP 691 EPOCH 1.18
STEP 692 EPOCH 1.18
STEP 693 EPOCH 1.18
STEP 694 EPOCH 1.19
STEP 695 EPOCH 1.19
STEP 696 EPOCH 1.19
STEP 697 EPOCH 1.19
STEP 698 EPOCH 1.19
STEP 699 EPOCH 1.19
STEP 700 EPOCH 1.20
LOG loss=0.3179, grad_norm=0.01026555709540844, learning_rate=2.337606837606838e-05, epoch=1.1965811965811965
STEP 701 EPOCH 1.20
STEP 702 EPOCH 1.20
STEP 703 EPOCH 1.20
STEP 704 EPOCH 1.20
STEP 705 EPOCH 1.21
STEP 706 EPOCH 1.21
STEP 707 EPOCH 1.21
STEP 708 EPOCH 1.21
STEP 709 EPOCH 1.21
STEP 710 EPOCH 1.21
LOG loss=0.0904, grad_norm=29.821269989013672, learning_rate=2.3233618233618236e-05, epoch=1.2136752136752136
STEP 711 EPOCH 1.22
STEP 712 EPOCH 1.22
STEP 713 EPOCH 1.22
STEP 714 EPOCH 1.22
STEP 715 EPOCH 1.22
STEP 716 EPOCH 1.22
STEP 717 EPOCH 1.23
STEP 718 EPOCH 1.23
STEP 719 EPOCH 1.23
STEP 720 EPOCH 1.23
LOG loss=0.0913, grad_norm=0.4906918704509735, learning_rate=2.3091168091168093e-05, epoch=1.2307692307692308
STEP 721 EPOCH 1.23
STEP 722 EPOCH 1.23
STEP 723 EPOCH 1.24
STEP 724 EPOCH 1.24
STEP 725 EPOCH 1.24
STEP 726 EPOCH 1.24
STEP 727 EPOCH 1.24
STEP 728 EPOCH 1.24
STEP 729 EPOCH 1.25
STEP 730 EPOCH 1.25
LOG loss=0.205, grad_norm=3.1657471656799316, learning_rate=2.2948717948717947e-05, epoch=1.2478632478632479
STEP 731 EPOCH 1.25
STEP 732 EPOCH 1.25
STEP 733 EPOCH 1.25
STEP 734 EPOCH 1.25
STEP 735 EPOCH 1.26
STEP 736 EPOCH 1.26
STEP 737 EPOCH 1.26
STEP 738 EPOCH 1.26
STEP 739 EPOCH 1.26
STEP 740 EPOCH 1.26
LOG loss=0.23, grad_norm=0.07707114517688751, learning_rate=2.2806267806267805e-05, epoch=1.264957264957265
STEP 741 EPOCH 1.27
STEP 742 EPOCH 1.27
STEP 743 EPOCH 1.27
STEP 744 EPOCH 1.27
STEP 745 EPOCH 1.27
STEP 746 EPOCH 1.28
STEP 747 EPOCH 1.28
STEP 748 EPOCH 1.28
STEP 749 EPOCH 1.28
STEP 750 EPOCH 1.28
LOG loss=0.1146, grad_norm=0.119752436876297, learning_rate=2.2663817663817662e-05, epoch=1.282051282051282
STEP 751 EPOCH 1.28
STEP 752 EPOCH 1.29
STEP 753 EPOCH 1.29
STEP 754 EPOCH 1.29
STEP 755 EPOCH 1.29
STEP 756 EPOCH 1.29
STEP 757 EPOCH 1.29
STEP 758 EPOCH 1.30
STEP 759 EPOCH 1.30
STEP 760 EPOCH 1.30
LOG loss=0.1076, grad_norm=0.012502512894570827, learning_rate=2.252136752136752e-05, epoch=1.2991452991452992
STEP 761 EPOCH 1.30
STEP 762 EPOCH 1.30
STEP 763 EPOCH 1.30
STEP 764 EPOCH 1.31
STEP 765 EPOCH 1.31
STEP 766 EPOCH 1.31
STEP 767 EPOCH 1.31
STEP 768 EPOCH 1.31
STEP 769 EPOCH 1.31
STEP 770 EPOCH 1.32
LOG loss=0.0512, grad_norm=8.044563293457031, learning_rate=2.2378917378917377e-05, epoch=1.3162393162393162
STEP 771 EPOCH 1.32
STEP 772 EPOCH 1.32
STEP 773 EPOCH 1.32
STEP 774 EPOCH 1.32
STEP 775 EPOCH 1.32
STEP 776 EPOCH 1.33
STEP 777 EPOCH 1.33
STEP 778 EPOCH 1.33
STEP 779 EPOCH 1.33
STEP 780 EPOCH 1.33
LOG loss=0.2158, grad_norm=6.989441394805908, learning_rate=2.2236467236467238e-05, epoch=1.3333333333333333
STEP 781 EPOCH 1.34
STEP 782 EPOCH 1.34
STEP 783 EPOCH 1.34
STEP 784 EPOCH 1.34
STEP 785 EPOCH 1.34
STEP 786 EPOCH 1.34
STEP 787 EPOCH 1.35
STEP 788 EPOCH 1.35
STEP 789 EPOCH 1.35
STEP 790 EPOCH 1.35
LOG loss=0.2086, grad_norm=55.741943359375, learning_rate=2.2094017094017095e-05, epoch=1.3504273504273505
STEP 791 EPOCH 1.35
STEP 792 EPOCH 1.35
STEP 793 EPOCH 1.36
STEP 794 EPOCH 1.36
STEP 795 EPOCH 1.36
STEP 796 EPOCH 1.36
STEP 797 EPOCH 1.36
STEP 798 EPOCH 1.36
STEP 799 EPOCH 1.37
STEP 800 EPOCH 1.37
LOG loss=0.0599, grad_norm=15.829954147338867, learning_rate=2.1951566951566952e-05, epoch=1.3675213675213675
STEP 801 EPOCH 1.37
STEP 802 EPOCH 1.37
STEP 803 EPOCH 1.37
STEP 804 EPOCH 1.37
STEP 805 EPOCH 1.38
STEP 806 EPOCH 1.38
STEP 807 EPOCH 1.38
STEP 808 EPOCH 1.38
STEP 809 EPOCH 1.38
STEP 810 EPOCH 1.38
LOG loss=0.024, grad_norm=0.014563580974936485, learning_rate=2.180911680911681e-05, epoch=1.3846153846153846
STEP 811 EPOCH 1.39
STEP 812 EPOCH 1.39
STEP 813 EPOCH 1.39
STEP 814 EPOCH 1.39
STEP 815 EPOCH 1.39
STEP 816 EPOCH 1.39
STEP 817 EPOCH 1.40
STEP 818 EPOCH 1.40
STEP 819 EPOCH 1.40
STEP 820 EPOCH 1.40
LOG loss=0.2807, grad_norm=14.648417472839355, learning_rate=2.1666666666666667e-05, epoch=1.4017094017094016
STEP 821 EPOCH 1.40
STEP 822 EPOCH 1.41
STEP 823 EPOCH 1.41
STEP 824 EPOCH 1.41
STEP 825 EPOCH 1.41
STEP 826 EPOCH 1.41
STEP 827 EPOCH 1.41
STEP 828 EPOCH 1.42
STEP 829 EPOCH 1.42
STEP 830 EPOCH 1.42
LOG loss=0.5055, grad_norm=121.1635513305664, learning_rate=2.1524216524216524e-05, epoch=1.4188034188034189
STEP 831 EPOCH 1.42
STEP 832 EPOCH 1.42
STEP 833 EPOCH 1.42
STEP 834 EPOCH 1.43
STEP 835 EPOCH 1.43
STEP 836 EPOCH 1.43
STEP 837 EPOCH 1.43
STEP 838 EPOCH 1.43
STEP 839 EPOCH 1.43
STEP 840 EPOCH 1.44
LOG loss=0.2111, grad_norm=0.314946711063385, learning_rate=2.1381766381766382e-05, epoch=1.435897435897436
STEP 841 EPOCH 1.44
STEP 842 EPOCH 1.44
STEP 843 EPOCH 1.44
STEP 844 EPOCH 1.44
STEP 845 EPOCH 1.44
STEP 846 EPOCH 1.45
STEP 847 EPOCH 1.45
STEP 848 EPOCH 1.45
STEP 849 EPOCH 1.45
STEP 850 EPOCH 1.45
LOG loss=0.1372, grad_norm=0.12843471765518188, learning_rate=2.123931623931624e-05, epoch=1.452991452991453
STEP 851 EPOCH 1.45
STEP 852 EPOCH 1.46
STEP 853 EPOCH 1.46
STEP 854 EPOCH 1.46
STEP 855 EPOCH 1.46
STEP 856 EPOCH 1.46
STEP 857 EPOCH 1.46
STEP 858 EPOCH 1.47
STEP 859 EPOCH 1.47
STEP 860 EPOCH 1.47
LOG loss=0.0724, grad_norm=0.8399816751480103, learning_rate=2.1096866096866097e-05, epoch=1.4700854700854702
STEP 861 EPOCH 1.47
STEP 862 EPOCH 1.47
STEP 863 EPOCH 1.48
STEP 864 EPOCH 1.48
STEP 865 EPOCH 1.48
STEP 866 EPOCH 1.48
STEP 867 EPOCH 1.48
STEP 868 EPOCH 1.48
STEP 869 EPOCH 1.49
STEP 870 EPOCH 1.49
LOG loss=0.1976, grad_norm=0.5528720617294312, learning_rate=2.0954415954415954e-05, epoch=1.4871794871794872
STEP 871 EPOCH 1.49
STEP 872 EPOCH 1.49
STEP 873 EPOCH 1.49
STEP 874 EPOCH 1.49
STEP 875 EPOCH 1.50
STEP 876 EPOCH 1.50
STEP 877 EPOCH 1.50
STEP 878 EPOCH 1.50
STEP 879 EPOCH 1.50
STEP 880 EPOCH 1.50
LOG loss=0.0939, grad_norm=0.6978510022163391, learning_rate=2.0811965811965815e-05, epoch=1.5042735042735043
STEP 881 EPOCH 1.51
STEP 882 EPOCH 1.51
STEP 883 EPOCH 1.51
STEP 884 EPOCH 1.51
STEP 885 EPOCH 1.51
STEP 886 EPOCH 1.51
STEP 887 EPOCH 1.52
STEP 888 EPOCH 1.52
STEP 889 EPOCH 1.52
STEP 890 EPOCH 1.52
LOG loss=0.1476, grad_norm=14.824689865112305, learning_rate=2.0669515669515672e-05, epoch=1.5213675213675213
STEP 891 EPOCH 1.52
STEP 892 EPOCH 1.52
STEP 893 EPOCH 1.53
STEP 894 EPOCH 1.53
STEP 895 EPOCH 1.53
STEP 896 EPOCH 1.53
STEP 897 EPOCH 1.53
STEP 898 EPOCH 1.54
STEP 899 EPOCH 1.54
STEP 900 EPOCH 1.54
LOG loss=0.0537, grad_norm=7.060474872589111, learning_rate=2.052706552706553e-05, epoch=1.5384615384615383
STEP 901 EPOCH 1.54
STEP 902 EPOCH 1.54
STEP 903 EPOCH 1.54
STEP 904 EPOCH 1.55
STEP 905 EPOCH 1.55
STEP 906 EPOCH 1.55
STEP 907 EPOCH 1.55
STEP 908 EPOCH 1.55
STEP 909 EPOCH 1.55
STEP 910 EPOCH 1.56
LOG loss=0.0545, grad_norm=11.464961051940918, learning_rate=2.0384615384615387e-05, epoch=1.5555555555555556
STEP 911 EPOCH 1.56
STEP 912 EPOCH 1.56
STEP 913 EPOCH 1.56
STEP 914 EPOCH 1.56
STEP 915 EPOCH 1.56
STEP 916 EPOCH 1.57
STEP 917 EPOCH 1.57
STEP 918 EPOCH 1.57
STEP 919 EPOCH 1.57
STEP 920 EPOCH 1.57
LOG loss=0.3094, grad_norm=0.33598724007606506, learning_rate=2.0242165242165244e-05, epoch=1.5726495726495726
STEP 921 EPOCH 1.57
STEP 922 EPOCH 1.58
STEP 923 EPOCH 1.58
STEP 924 EPOCH 1.58
STEP 925 EPOCH 1.58
STEP 926 EPOCH 1.58
STEP 927 EPOCH 1.58
STEP 928 EPOCH 1.59
STEP 929 EPOCH 1.59
STEP 930 EPOCH 1.59
LOG loss=0.2312, grad_norm=0.14197582006454468, learning_rate=2.00997150997151e-05, epoch=1.5897435897435899
STEP 931 EPOCH 1.59
STEP 932 EPOCH 1.59
STEP 933 EPOCH 1.59
STEP 934 EPOCH 1.60
STEP 935 EPOCH 1.60
STEP 936 EPOCH 1.60
STEP 937 EPOCH 1.60
STEP 938 EPOCH 1.60
STEP 939 EPOCH 1.61
STEP 940 EPOCH 1.61
LOG loss=0.1081, grad_norm=0.14736638963222504, learning_rate=1.995726495726496e-05, epoch=1.606837606837607
STEP 941 EPOCH 1.61
STEP 942 EPOCH 1.61
STEP 943 EPOCH 1.61
STEP 944 EPOCH 1.61
STEP 945 EPOCH 1.62
STEP 946 EPOCH 1.62
STEP 947 EPOCH 1.62
STEP 948 EPOCH 1.62
STEP 949 EPOCH 1.62
STEP 950 EPOCH 1.62
LOG loss=0.1635, grad_norm=10.089132308959961, learning_rate=1.9814814814814816e-05, epoch=1.623931623931624
STEP 951 EPOCH 1.63
STEP 952 EPOCH 1.63
STEP 953 EPOCH 1.63
STEP 954 EPOCH 1.63
STEP 955 EPOCH 1.63
STEP 956 EPOCH 1.63
STEP 957 EPOCH 1.64
STEP 958 EPOCH 1.64
STEP 959 EPOCH 1.64
STEP 960 EPOCH 1.64
LOG loss=0.3134, grad_norm=31.24953269958496, learning_rate=1.9672364672364674e-05, epoch=1.641025641025641
STEP 961 EPOCH 1.64
STEP 962 EPOCH 1.64
STEP 963 EPOCH 1.65
STEP 964 EPOCH 1.65
STEP 965 EPOCH 1.65
STEP 966 EPOCH 1.65
STEP 967 EPOCH 1.65
STEP 968 EPOCH 1.65
STEP 969 EPOCH 1.66
STEP 970 EPOCH 1.66
LOG loss=0.1084, grad_norm=0.22968946397304535, learning_rate=1.9529914529914528e-05, epoch=1.658119658119658
STEP 971 EPOCH 1.66
STEP 972 EPOCH 1.66
STEP 973 EPOCH 1.66
STEP 974 EPOCH 1.66
STEP 975 EPOCH 1.67
STEP 976 EPOCH 1.67
STEP 977 EPOCH 1.67
STEP 978 EPOCH 1.67
STEP 979 EPOCH 1.67
STEP 980 EPOCH 1.68
LOG loss=0.176, grad_norm=0.4277762174606323, learning_rate=1.9387464387464385e-05, epoch=1.6752136752136753
STEP 981 EPOCH 1.68
STEP 982 EPOCH 1.68
STEP 983 EPOCH 1.68
STEP 984 EPOCH 1.68
STEP 985 EPOCH 1.68
STEP 986 EPOCH 1.69
STEP 987 EPOCH 1.69
STEP 988 EPOCH 1.69
STEP 989 EPOCH 1.69
STEP 990 EPOCH 1.69
LOG loss=0.0534, grad_norm=1.0246756076812744, learning_rate=1.9245014245014246e-05, epoch=1.6923076923076923
STEP 991 EPOCH 1.69
STEP 992 EPOCH 1.70
STEP 993 EPOCH 1.70
STEP 994 EPOCH 1.70
STEP 995 EPOCH 1.70
STEP 996 EPOCH 1.70
STEP 997 EPOCH 1.70
STEP 998 EPOCH 1.71
STEP 999 EPOCH 1.71
STEP 1000 EPOCH 1.71
LOG loss=0.1204, grad_norm=0.0711313858628273, learning_rate=1.9102564102564103e-05, epoch=1.7094017094017095
STEP 1001 EPOCH 1.71
STEP 1002 EPOCH 1.71
STEP 1003 EPOCH 1.71
STEP 1004 EPOCH 1.72
STEP 1005 EPOCH 1.72
STEP 1006 EPOCH 1.72
STEP 1007 EPOCH 1.72
STEP 1008 EPOCH 1.72
STEP 1009 EPOCH 1.72
STEP 1010 EPOCH 1.73
LOG loss=0.0765, grad_norm=0.09874356538057327, learning_rate=1.896011396011396e-05, epoch=1.7264957264957266
STEP 1011 EPOCH 1.73
STEP 1012 EPOCH 1.73
STEP 1013 EPOCH 1.73
STEP 1014 EPOCH 1.73
STEP 1015 EPOCH 1.74
STEP 1016 EPOCH 1.74
STEP 1017 EPOCH 1.74
STEP 1018 EPOCH 1.74
STEP 1019 EPOCH 1.74
STEP 1020 EPOCH 1.74
LOG loss=0.0971, grad_norm=0.09655403345823288, learning_rate=1.8817663817663818e-05, epoch=1.7435897435897436
STEP 1021 EPOCH 1.75
STEP 1022 EPOCH 1.75
STEP 1023 EPOCH 1.75
STEP 1024 EPOCH 1.75
STEP 1025 EPOCH 1.75
STEP 1026 EPOCH 1.75
STEP 1027 EPOCH 1.76
STEP 1028 EPOCH 1.76
STEP 1029 EPOCH 1.76
STEP 1030 EPOCH 1.76
LOG loss=0.0293, grad_norm=0.17732922732830048, learning_rate=1.8675213675213675e-05, epoch=1.7606837606837606
STEP 1031 EPOCH 1.76
STEP 1032 EPOCH 1.76
STEP 1033 EPOCH 1.77
STEP 1034 EPOCH 1.77
STEP 1035 EPOCH 1.77
STEP 1036 EPOCH 1.77
STEP 1037 EPOCH 1.77
STEP 1038 EPOCH 1.77
STEP 1039 EPOCH 1.78
STEP 1040 EPOCH 1.78
LOG loss=0.1995, grad_norm=0.0009514674893580377, learning_rate=1.8532763532763533e-05, epoch=1.7777777777777777
STEP 1041 EPOCH 1.78
STEP 1042 EPOCH 1.78
STEP 1043 EPOCH 1.78
STEP 1044 EPOCH 1.78
STEP 1045 EPOCH 1.79
STEP 1046 EPOCH 1.79
STEP 1047 EPOCH 1.79
STEP 1048 EPOCH 1.79
STEP 1049 EPOCH 1.79
STEP 1050 EPOCH 1.79
LOG loss=0.0272, grad_norm=0.7829301953315735, learning_rate=1.839031339031339e-05, epoch=1.7948717948717947
STEP 1051 EPOCH 1.80
STEP 1052 EPOCH 1.80
STEP 1053 EPOCH 1.80
STEP 1054 EPOCH 1.80
STEP 1055 EPOCH 1.80
STEP 1056 EPOCH 1.81
STEP 1057 EPOCH 1.81
STEP 1058 EPOCH 1.81
STEP 1059 EPOCH 1.81
STEP 1060 EPOCH 1.81
LOG loss=0.0747, grad_norm=4.014549732208252, learning_rate=1.8247863247863247e-05, epoch=1.811965811965812
STEP 1061 EPOCH 1.81
STEP 1062 EPOCH 1.82
STEP 1063 EPOCH 1.82
STEP 1064 EPOCH 1.82
STEP 1065 EPOCH 1.82
STEP 1066 EPOCH 1.82
STEP 1067 EPOCH 1.82
STEP 1068 EPOCH 1.83
STEP 1069 EPOCH 1.83
STEP 1070 EPOCH 1.83
LOG loss=0.3052, grad_norm=0.009858674369752407, learning_rate=1.8105413105413105e-05, epoch=1.8290598290598292
STEP 1071 EPOCH 1.83
STEP 1072 EPOCH 1.83
STEP 1073 EPOCH 1.83
STEP 1074 EPOCH 1.84
STEP 1075 EPOCH 1.84
STEP 1076 EPOCH 1.84
STEP 1077 EPOCH 1.84
STEP 1078 EPOCH 1.84
STEP 1079 EPOCH 1.84
STEP 1080 EPOCH 1.85
LOG loss=0.1255, grad_norm=0.12991386651992798, learning_rate=1.7962962962962962e-05, epoch=1.8461538461538463
STEP 1081 EPOCH 1.85
STEP 1082 EPOCH 1.85
STEP 1083 EPOCH 1.85
STEP 1084 EPOCH 1.85
STEP 1085 EPOCH 1.85
STEP 1086 EPOCH 1.86
STEP 1087 EPOCH 1.86
STEP 1088 EPOCH 1.86
STEP 1089 EPOCH 1.86
STEP 1090 EPOCH 1.86
LOG loss=0.02, grad_norm=0.3100418448448181, learning_rate=1.782051282051282e-05, epoch=1.8632478632478633
STEP 1091 EPOCH 1.86
STEP 1092 EPOCH 1.87
STEP 1093 EPOCH 1.87
STEP 1094 EPOCH 1.87
STEP 1095 EPOCH 1.87
STEP 1096 EPOCH 1.87
STEP 1097 EPOCH 1.88
STEP 1098 EPOCH 1.88
STEP 1099 EPOCH 1.88
STEP 1100 EPOCH 1.88
LOG loss=0.0434, grad_norm=7.543466091156006, learning_rate=1.767806267806268e-05, epoch=1.8803418803418803
STEP 1101 EPOCH 1.88
STEP 1102 EPOCH 1.88
STEP 1103 EPOCH 1.89
STEP 1104 EPOCH 1.89
STEP 1105 EPOCH 1.89
STEP 1106 EPOCH 1.89
STEP 1107 EPOCH 1.89
STEP 1108 EPOCH 1.89
STEP 1109 EPOCH 1.90
STEP 1110 EPOCH 1.90
LOG loss=0.0694, grad_norm=5.818853855133057, learning_rate=1.7535612535612538e-05, epoch=1.8974358974358974
STEP 1111 EPOCH 1.90
STEP 1112 EPOCH 1.90
STEP 1113 EPOCH 1.90
STEP 1114 EPOCH 1.90
STEP 1115 EPOCH 1.91
STEP 1116 EPOCH 1.91
STEP 1117 EPOCH 1.91
STEP 1118 EPOCH 1.91
STEP 1119 EPOCH 1.91
STEP 1120 EPOCH 1.91
LOG loss=0.0057, grad_norm=0.1430238038301468, learning_rate=1.7393162393162395e-05, epoch=1.9145299145299144
STEP 1121 EPOCH 1.92
STEP 1122 EPOCH 1.92
STEP 1123 EPOCH 1.92
STEP 1124 EPOCH 1.92
STEP 1125 EPOCH 1.92
STEP 1126 EPOCH 1.92
STEP 1127 EPOCH 1.93
STEP 1128 EPOCH 1.93
STEP 1129 EPOCH 1.93
STEP 1130 EPOCH 1.93
LOG loss=0.2214, grad_norm=57.68163299560547, learning_rate=1.7250712250712252e-05, epoch=1.9316239316239316
STEP 1131 EPOCH 1.93
STEP 1132 EPOCH 1.94
STEP 1133 EPOCH 1.94
STEP 1134 EPOCH 1.94
STEP 1135 EPOCH 1.94
STEP 1136 EPOCH 1.94
STEP 1137 EPOCH 1.94
STEP 1138 EPOCH 1.95
STEP 1139 EPOCH 1.95
STEP 1140 EPOCH 1.95
LOG loss=0.0863, grad_norm=0.15849679708480835, learning_rate=1.710826210826211e-05, epoch=1.9487179487179487
STEP 1141 EPOCH 1.95
STEP 1142 EPOCH 1.95
STEP 1143 EPOCH 1.95
STEP 1144 EPOCH 1.96
STEP 1145 EPOCH 1.96
STEP 1146 EPOCH 1.96
STEP 1147 EPOCH 1.96
STEP 1148 EPOCH 1.96
STEP 1149 EPOCH 1.96
STEP 1150 EPOCH 1.97
LOG loss=0.2142, grad_norm=0.3767992854118347, learning_rate=1.6965811965811967e-05, epoch=1.965811965811966
STEP 1151 EPOCH 1.97
STEP 1152 EPOCH 1.97
STEP 1153 EPOCH 1.97
STEP 1154 EPOCH 1.97
STEP 1155 EPOCH 1.97
STEP 1156 EPOCH 1.98
STEP 1157 EPOCH 1.98
STEP 1158 EPOCH 1.98
STEP 1159 EPOCH 1.98
STEP 1160 EPOCH 1.98
LOG loss=0.0853, grad_norm=0.24163700640201569, learning_rate=1.6823361823361824e-05, epoch=1.982905982905983
STEP 1161 EPOCH 1.98
STEP 1162 EPOCH 1.99
STEP 1163 EPOCH 1.99
STEP 1164 EPOCH 1.99
STEP 1165 EPOCH 1.99
STEP 1166 EPOCH 1.99
STEP 1167 EPOCH 1.99
STEP 1168 EPOCH 2.00
STEP 1169 EPOCH 2.00
STEP 1170 EPOCH 2.00
LOG loss=0.0942, grad_norm=0.06400017440319061, learning_rate=1.6680911680911682e-05, epoch=2.0
STEP 1171 EPOCH 2.00
STEP 1172 EPOCH 2.00
STEP 1173 EPOCH 2.01
STEP 1174 EPOCH 2.01
STEP 1175 EPOCH 2.01
STEP 1176 EPOCH 2.01
STEP 1177 EPOCH 2.01
STEP 1178 EPOCH 2.01
STEP 1179 EPOCH 2.02
STEP 1180 EPOCH 2.02
LOG loss=0.1304, grad_norm=0.03497232124209404, learning_rate=1.653846153846154e-05, epoch=2.017094017094017
STEP 1181 EPOCH 2.02
STEP 1182 EPOCH 2.02
STEP 1183 EPOCH 2.02
STEP 1184 EPOCH 2.02
STEP 1185 EPOCH 2.03
STEP 1186 EPOCH 2.03
STEP 1187 EPOCH 2.03
STEP 1188 EPOCH 2.03
STEP 1189 EPOCH 2.03
STEP 1190 EPOCH 2.03
LOG loss=0.0835, grad_norm=0.008276449516415596, learning_rate=1.6396011396011396e-05, epoch=2.034188034188034
STEP 1191 EPOCH 2.04
STEP 1192 EPOCH 2.04
STEP 1193 EPOCH 2.04
STEP 1194 EPOCH 2.04
STEP 1195 EPOCH 2.04
STEP 1196 EPOCH 2.04
STEP 1197 EPOCH 2.05
STEP 1198 EPOCH 2.05
STEP 1199 EPOCH 2.05
STEP 1200 EPOCH 2.05
LOG loss=0.0252, grad_norm=0.06065165624022484, learning_rate=1.6253561253561254e-05, epoch=2.051282051282051
STEP 1201 EPOCH 2.05
STEP 1202 EPOCH 2.05
STEP 1203 EPOCH 2.06
STEP 1204 EPOCH 2.06
STEP 1205 EPOCH 2.06
STEP 1206 EPOCH 2.06
STEP 1207 EPOCH 2.06
STEP 1208 EPOCH 2.06
STEP 1209 EPOCH 2.07
STEP 1210 EPOCH 2.07
LOG loss=0.2076, grad_norm=11.936545372009277, learning_rate=1.6111111111111115e-05, epoch=2.0683760683760686
STEP 1211 EPOCH 2.07
STEP 1212 EPOCH 2.07
STEP 1213 EPOCH 2.07
STEP 1214 EPOCH 2.08
STEP 1215 EPOCH 2.08
STEP 1216 EPOCH 2.08
STEP 1217 EPOCH 2.08
STEP 1218 EPOCH 2.08
STEP 1219 EPOCH 2.08
STEP 1220 EPOCH 2.09
LOG loss=0.0967, grad_norm=0.23255841434001923, learning_rate=1.596866096866097e-05, epoch=2.0854700854700856
STEP 1221 EPOCH 2.09
STEP 1222 EPOCH 2.09
STEP 1223 EPOCH 2.09
STEP 1224 EPOCH 2.09
STEP 1225 EPOCH 2.09
STEP 1226 EPOCH 2.10
STEP 1227 EPOCH 2.10
STEP 1228 EPOCH 2.10
STEP 1229 EPOCH 2.10
STEP 1230 EPOCH 2.10
LOG loss=0.0103, grad_norm=24.42828369140625, learning_rate=1.5826210826210826e-05, epoch=2.1025641025641026
STEP 1231 EPOCH 2.10
STEP 1232 EPOCH 2.11
STEP 1233 EPOCH 2.11
STEP 1234 EPOCH 2.11
STEP 1235 EPOCH 2.11
STEP 1236 EPOCH 2.11
STEP 1237 EPOCH 2.11
STEP 1238 EPOCH 2.12
STEP 1239 EPOCH 2.12
STEP 1240 EPOCH 2.12
LOG loss=0.0818, grad_norm=0.18323633074760437, learning_rate=1.5683760683760683e-05, epoch=2.1196581196581197
STEP 1241 EPOCH 2.12
STEP 1242 EPOCH 2.12
STEP 1243 EPOCH 2.12
STEP 1244 EPOCH 2.13
STEP 1245 EPOCH 2.13
STEP 1246 EPOCH 2.13
STEP 1247 EPOCH 2.13
STEP 1248 EPOCH 2.13
STEP 1249 EPOCH 2.14
STEP 1250 EPOCH 2.14
LOG loss=0.3554, grad_norm=8.624157905578613, learning_rate=1.554131054131054e-05, epoch=2.1367521367521367
STEP 1251 EPOCH 2.14
STEP 1252 EPOCH 2.14
STEP 1253 EPOCH 2.14
STEP 1254 EPOCH 2.14
STEP 1255 EPOCH 2.15
STEP 1256 EPOCH 2.15
STEP 1257 EPOCH 2.15
STEP 1258 EPOCH 2.15
STEP 1259 EPOCH 2.15
STEP 1260 EPOCH 2.15
LOG loss=0.0623, grad_norm=0.07274512201547623, learning_rate=1.5398860398860398e-05, epoch=2.1538461538461537
STEP 1261 EPOCH 2.16
STEP 1262 EPOCH 2.16
STEP 1263 EPOCH 2.16
STEP 1264 EPOCH 2.16
STEP 1265 EPOCH 2.16
STEP 1266 EPOCH 2.16
STEP 1267 EPOCH 2.17
STEP 1268 EPOCH 2.17
STEP 1269 EPOCH 2.17
STEP 1270 EPOCH 2.17
LOG loss=0.0971, grad_norm=45.519840240478516, learning_rate=1.5256410256410255e-05, epoch=2.1709401709401708
STEP 1271 EPOCH 2.17
STEP 1272 EPOCH 2.17
STEP 1273 EPOCH 2.18
STEP 1274 EPOCH 2.18
STEP 1275 EPOCH 2.18
STEP 1276 EPOCH 2.18
STEP 1277 EPOCH 2.18
STEP 1278 EPOCH 2.18
STEP 1279 EPOCH 2.19
STEP 1280 EPOCH 2.19
LOG loss=0.003, grad_norm=1.5427244901657104, learning_rate=1.5113960113960113e-05, epoch=2.1880341880341883
STEP 1281 EPOCH 2.19
STEP 1282 EPOCH 2.19
STEP 1283 EPOCH 2.19
STEP 1284 EPOCH 2.19
STEP 1285 EPOCH 2.20
STEP 1286 EPOCH 2.20
STEP 1287 EPOCH 2.20
STEP 1288 EPOCH 2.20
STEP 1289 EPOCH 2.20
STEP 1290 EPOCH 2.21
LOG loss=0.1169, grad_norm=0.853823721408844, learning_rate=1.4971509971509972e-05, epoch=2.2051282051282053
STEP 1291 EPOCH 2.21
STEP 1292 EPOCH 2.21
STEP 1293 EPOCH 2.21
STEP 1294 EPOCH 2.21
STEP 1295 EPOCH 2.21
STEP 1296 EPOCH 2.22
STEP 1297 EPOCH 2.22
STEP 1298 EPOCH 2.22
STEP 1299 EPOCH 2.22
STEP 1300 EPOCH 2.22
LOG loss=0.0352, grad_norm=1.559716820716858, learning_rate=1.482905982905983e-05, epoch=2.2222222222222223
STEP 1301 EPOCH 2.22
STEP 1302 EPOCH 2.23
STEP 1303 EPOCH 2.23
STEP 1304 EPOCH 2.23
STEP 1305 EPOCH 2.23
STEP 1306 EPOCH 2.23
STEP 1307 EPOCH 2.23
STEP 1308 EPOCH 2.24
STEP 1309 EPOCH 2.24
STEP 1310 EPOCH 2.24
LOG loss=0.1286, grad_norm=0.011560231447219849, learning_rate=1.4686609686609687e-05, epoch=2.2393162393162394
STEP 1311 EPOCH 2.24
STEP 1312 EPOCH 2.24
STEP 1313 EPOCH 2.24
STEP 1314 EPOCH 2.25
STEP 1315 EPOCH 2.25
STEP 1316 EPOCH 2.25
STEP 1317 EPOCH 2.25
STEP 1318 EPOCH 2.25
STEP 1319 EPOCH 2.25
STEP 1320 EPOCH 2.26
LOG loss=0.058, grad_norm=0.04798543080687523, learning_rate=1.4544159544159544e-05, epoch=2.2564102564102564
STEP 1321 EPOCH 2.26
STEP 1322 EPOCH 2.26
STEP 1323 EPOCH 2.26
STEP 1324 EPOCH 2.26
STEP 1325 EPOCH 2.26
STEP 1326 EPOCH 2.27
STEP 1327 EPOCH 2.27
STEP 1328 EPOCH 2.27
STEP 1329 EPOCH 2.27
STEP 1330 EPOCH 2.27
LOG loss=0.1214, grad_norm=0.0024186333175748587, learning_rate=1.4401709401709401e-05, epoch=2.2735042735042734
STEP 1331 EPOCH 2.28
STEP 1332 EPOCH 2.28
STEP 1333 EPOCH 2.28
STEP 1334 EPOCH 2.28
STEP 1335 EPOCH 2.28
STEP 1336 EPOCH 2.28
STEP 1337 EPOCH 2.29
STEP 1338 EPOCH 2.29
STEP 1339 EPOCH 2.29
STEP 1340 EPOCH 2.29
LOG loss=0.1217, grad_norm=85.3410415649414, learning_rate=1.425925925925926e-05, epoch=2.2905982905982905
STEP 1341 EPOCH 2.29
STEP 1342 EPOCH 2.29
STEP 1343 EPOCH 2.30
STEP 1344 EPOCH 2.30
STEP 1345 EPOCH 2.30
STEP 1346 EPOCH 2.30
STEP 1347 EPOCH 2.30
STEP 1348 EPOCH 2.30
STEP 1349 EPOCH 2.31
STEP 1350 EPOCH 2.31
LOG loss=0.1531, grad_norm=121.04521942138672, learning_rate=1.4116809116809118e-05, epoch=2.3076923076923075
STEP 1351 EPOCH 2.31
STEP 1352 EPOCH 2.31
STEP 1353 EPOCH 2.31
STEP 1354 EPOCH 2.31
STEP 1355 EPOCH 2.32
STEP 1356 EPOCH 2.32
STEP 1357 EPOCH 2.32
STEP 1358 EPOCH 2.32
STEP 1359 EPOCH 2.32
STEP 1360 EPOCH 2.32
LOG loss=0.1836, grad_norm=19.066862106323242, learning_rate=1.3974358974358975e-05, epoch=2.324786324786325
STEP 1361 EPOCH 2.33
STEP 1362 EPOCH 2.33
STEP 1363 EPOCH 2.33
STEP 1364 EPOCH 2.33
STEP 1365 EPOCH 2.33
STEP 1366 EPOCH 2.34
STEP 1367 EPOCH 2.34
STEP 1368 EPOCH 2.34
STEP 1369 EPOCH 2.34
STEP 1370 EPOCH 2.34
LOG loss=0.0618, grad_norm=0.012900946661829948, learning_rate=1.3831908831908833e-05, epoch=2.341880341880342
STEP 1371 EPOCH 2.34
STEP 1372 EPOCH 2.35
STEP 1373 EPOCH 2.35
STEP 1374 EPOCH 2.35
STEP 1375 EPOCH 2.35
STEP 1376 EPOCH 2.35
STEP 1377 EPOCH 2.35
STEP 1378 EPOCH 2.36
STEP 1379 EPOCH 2.36
STEP 1380 EPOCH 2.36
LOG loss=0.1719, grad_norm=0.3959430158138275, learning_rate=1.368945868945869e-05, epoch=2.358974358974359
STEP 1381 EPOCH 2.36
STEP 1382 EPOCH 2.36
STEP 1383 EPOCH 2.36
STEP 1384 EPOCH 2.37
STEP 1385 EPOCH 2.37
STEP 1386 EPOCH 2.37
STEP 1387 EPOCH 2.37
STEP 1388 EPOCH 2.37
STEP 1389 EPOCH 2.37
STEP 1390 EPOCH 2.38
LOG loss=0.21, grad_norm=90.26721954345703, learning_rate=1.3547008547008547e-05, epoch=2.376068376068376
STEP 1391 EPOCH 2.38
STEP 1392 EPOCH 2.38
STEP 1393 EPOCH 2.38
STEP 1394 EPOCH 2.38
STEP 1395 EPOCH 2.38
STEP 1396 EPOCH 2.39
STEP 1397 EPOCH 2.39
STEP 1398 EPOCH 2.39
STEP 1399 EPOCH 2.39
STEP 1400 EPOCH 2.39
LOG loss=0.1486, grad_norm=0.10057520866394043, learning_rate=1.3404558404558405e-05, epoch=2.393162393162393
STEP 1401 EPOCH 2.39
STEP 1402 EPOCH 2.40
STEP 1403 EPOCH 2.40
STEP 1404 EPOCH 2.40
STEP 1405 EPOCH 2.40
STEP 1406 EPOCH 2.40
STEP 1407 EPOCH 2.41
STEP 1408 EPOCH 2.41
STEP 1409 EPOCH 2.41
STEP 1410 EPOCH 2.41
LOG loss=0.0339, grad_norm=0.001506565953604877, learning_rate=1.3262108262108262e-05, epoch=2.41025641025641
STEP 1411 EPOCH 2.41
STEP 1412 EPOCH 2.41
STEP 1413 EPOCH 2.42
STEP 1414 EPOCH 2.42
STEP 1415 EPOCH 2.42
STEP 1416 EPOCH 2.42
STEP 1417 EPOCH 2.42
STEP 1418 EPOCH 2.42
STEP 1419 EPOCH 2.43
STEP 1420 EPOCH 2.43
LOG loss=0.0851, grad_norm=3.387410879135132, learning_rate=1.311965811965812e-05, epoch=2.427350427350427
STEP 1421 EPOCH 2.43
STEP 1422 EPOCH 2.43
STEP 1423 EPOCH 2.43
STEP 1424 EPOCH 2.43
STEP 1425 EPOCH 2.44
STEP 1426 EPOCH 2.44
STEP 1427 EPOCH 2.44
STEP 1428 EPOCH 2.44
STEP 1429 EPOCH 2.44
STEP 1430 EPOCH 2.44
LOG loss=0.2526, grad_norm=38.965606689453125, learning_rate=1.2977207977207977e-05, epoch=2.4444444444444446
STEP 1431 EPOCH 2.45
STEP 1432 EPOCH 2.45
STEP 1433 EPOCH 2.45
STEP 1434 EPOCH 2.45
STEP 1435 EPOCH 2.45
STEP 1436 EPOCH 2.45
STEP 1437 EPOCH 2.46
STEP 1438 EPOCH 2.46
STEP 1439 EPOCH 2.46
STEP 1440 EPOCH 2.46
LOG loss=0.3082, grad_norm=1.7970507144927979, learning_rate=1.2834757834757834e-05, epoch=2.4615384615384617
STEP 1441 EPOCH 2.46
STEP 1442 EPOCH 2.46
STEP 1443 EPOCH 2.47
STEP 1444 EPOCH 2.47
STEP 1445 EPOCH 2.47
STEP 1446 EPOCH 2.47
STEP 1447 EPOCH 2.47
STEP 1448 EPOCH 2.48
STEP 1449 EPOCH 2.48
STEP 1450 EPOCH 2.48
LOG loss=0.1644, grad_norm=6.476560592651367, learning_rate=1.2692307692307693e-05, epoch=2.4786324786324787
STEP 1451 EPOCH 2.48
STEP 1452 EPOCH 2.48
STEP 1453 EPOCH 2.48
STEP 1454 EPOCH 2.49
STEP 1455 EPOCH 2.49
STEP 1456 EPOCH 2.49
STEP 1457 EPOCH 2.49
STEP 1458 EPOCH 2.49
STEP 1459 EPOCH 2.49
STEP 1460 EPOCH 2.50
LOG loss=0.1802, grad_norm=0.03444024547934532, learning_rate=1.254985754985755e-05, epoch=2.4957264957264957
STEP 1461 EPOCH 2.50
STEP 1462 EPOCH 2.50
STEP 1463 EPOCH 2.50
STEP 1464 EPOCH 2.50
STEP 1465 EPOCH 2.50
STEP 1466 EPOCH 2.51
STEP 1467 EPOCH 2.51
STEP 1468 EPOCH 2.51
STEP 1469 EPOCH 2.51
STEP 1470 EPOCH 2.51
LOG loss=0.1284, grad_norm=0.11681881546974182, learning_rate=1.2407407407407408e-05, epoch=2.5128205128205128
STEP 1471 EPOCH 2.51
STEP 1472 EPOCH 2.52
STEP 1473 EPOCH 2.52
STEP 1474 EPOCH 2.52
STEP 1475 EPOCH 2.52
STEP 1476 EPOCH 2.52
STEP 1477 EPOCH 2.52
STEP 1478 EPOCH 2.53
STEP 1479 EPOCH 2.53
STEP 1480 EPOCH 2.53
LOG loss=0.2209, grad_norm=146.3831024169922, learning_rate=1.2264957264957265e-05, epoch=2.52991452991453
STEP 1481 EPOCH 2.53
STEP 1482 EPOCH 2.53
STEP 1483 EPOCH 2.54
STEP 1484 EPOCH 2.54
STEP 1485 EPOCH 2.54
STEP 1486 EPOCH 2.54
STEP 1487 EPOCH 2.54
STEP 1488 EPOCH 2.54
STEP 1489 EPOCH 2.55
STEP 1490 EPOCH 2.55
LOG loss=0.0965, grad_norm=0.34230509400367737, learning_rate=1.2122507122507123e-05, epoch=2.547008547008547
STEP 1491 EPOCH 2.55
STEP 1492 EPOCH 2.55
STEP 1493 EPOCH 2.55
STEP 1494 EPOCH 2.55
STEP 1495 EPOCH 2.56
STEP 1496 EPOCH 2.56
STEP 1497 EPOCH 2.56
STEP 1498 EPOCH 2.56
STEP 1499 EPOCH 2.56
STEP 1500 EPOCH 2.56
LOG loss=0.0786, grad_norm=14.014530181884766, learning_rate=1.1980056980056982e-05, epoch=2.564102564102564
STEP 1501 EPOCH 2.57
STEP 1502 EPOCH 2.57
STEP 1503 EPOCH 2.57
STEP 1504 EPOCH 2.57
STEP 1505 EPOCH 2.57
STEP 1506 EPOCH 2.57
STEP 1507 EPOCH 2.58
STEP 1508 EPOCH 2.58
STEP 1509 EPOCH 2.58
STEP 1510 EPOCH 2.58
LOG loss=0.0729, grad_norm=2.085880756378174, learning_rate=1.1837606837606839e-05, epoch=2.5811965811965814
STEP 1511 EPOCH 2.58
STEP 1512 EPOCH 2.58
STEP 1513 EPOCH 2.59
STEP 1514 EPOCH 2.59
STEP 1515 EPOCH 2.59
STEP 1516 EPOCH 2.59
STEP 1517 EPOCH 2.59
STEP 1518 EPOCH 2.59
STEP 1519 EPOCH 2.60
STEP 1520 EPOCH 2.60
LOG loss=0.1364, grad_norm=20.081636428833008, learning_rate=1.1695156695156696e-05, epoch=2.5982905982905984
STEP 1521 EPOCH 2.60
STEP 1522 EPOCH 2.60
STEP 1523 EPOCH 2.60
STEP 1524 EPOCH 2.61
STEP 1525 EPOCH 2.61
STEP 1526 EPOCH 2.61
STEP 1527 EPOCH 2.61
STEP 1528 EPOCH 2.61
STEP 1529 EPOCH 2.61
STEP 1530 EPOCH 2.62
LOG loss=0.3766, grad_norm=79.95423126220703, learning_rate=1.1552706552706552e-05, epoch=2.6153846153846154
STEP 1531 EPOCH 2.62
STEP 1532 EPOCH 2.62
STEP 1533 EPOCH 2.62
STEP 1534 EPOCH 2.62
STEP 1535 EPOCH 2.62
STEP 1536 EPOCH 2.63
STEP 1537 EPOCH 2.63
STEP 1538 EPOCH 2.63
STEP 1539 EPOCH 2.63
STEP 1540 EPOCH 2.63
LOG loss=0.0684, grad_norm=7.680079460144043, learning_rate=1.141025641025641e-05, epoch=2.6324786324786325
STEP 1541 EPOCH 2.63
STEP 1542 EPOCH 2.64
STEP 1543 EPOCH 2.64
STEP 1544 EPOCH 2.64
STEP 1545 EPOCH 2.64
STEP 1546 EPOCH 2.64
STEP 1547 EPOCH 2.64
STEP 1548 EPOCH 2.65
STEP 1549 EPOCH 2.65
STEP 1550 EPOCH 2.65
LOG loss=0.3617, grad_norm=93.96792602539062, learning_rate=1.1267806267806267e-05, epoch=2.6495726495726495
STEP 1551 EPOCH 2.65
STEP 1552 EPOCH 2.65
STEP 1553 EPOCH 2.65
STEP 1554 EPOCH 2.66
STEP 1555 EPOCH 2.66
STEP 1556 EPOCH 2.66
STEP 1557 EPOCH 2.66
STEP 1558 EPOCH 2.66
STEP 1559 EPOCH 2.66
STEP 1560 EPOCH 2.67
LOG loss=0.4002, grad_norm=59.348514556884766, learning_rate=1.1125356125356126e-05, epoch=2.6666666666666665
STEP 1561 EPOCH 2.67
STEP 1562 EPOCH 2.67
STEP 1563 EPOCH 2.67
STEP 1564 EPOCH 2.67
STEP 1565 EPOCH 2.68
STEP 1566 EPOCH 2.68
STEP 1567 EPOCH 2.68
STEP 1568 EPOCH 2.68
STEP 1569 EPOCH 2.68
STEP 1570 EPOCH 2.68
LOG loss=0.2143, grad_norm=0.016782958060503006, learning_rate=1.0982905982905983e-05, epoch=2.683760683760684
STEP 1571 EPOCH 2.69
STEP 1572 EPOCH 2.69
STEP 1573 EPOCH 2.69
STEP 1574 EPOCH 2.69
STEP 1575 EPOCH 2.69
STEP 1576 EPOCH 2.69
STEP 1577 EPOCH 2.70
STEP 1578 EPOCH 2.70
STEP 1579 EPOCH 2.70
STEP 1580 EPOCH 2.70
LOG loss=0.1535, grad_norm=14.281084060668945, learning_rate=1.084045584045584e-05, epoch=2.700854700854701
STEP 1581 EPOCH 2.70
STEP 1582 EPOCH 2.70
STEP 1583 EPOCH 2.71
STEP 1584 EPOCH 2.71
STEP 1585 EPOCH 2.71
STEP 1586 EPOCH 2.71
STEP 1587 EPOCH 2.71
STEP 1588 EPOCH 2.71
STEP 1589 EPOCH 2.72
STEP 1590 EPOCH 2.72
LOG loss=0.227, grad_norm=1.621367335319519, learning_rate=1.0698005698005698e-05, epoch=2.717948717948718
STEP 1591 EPOCH 2.72
STEP 1592 EPOCH 2.72
STEP 1593 EPOCH 2.72
STEP 1594 EPOCH 2.72
STEP 1595 EPOCH 2.73
STEP 1596 EPOCH 2.73
STEP 1597 EPOCH 2.73
STEP 1598 EPOCH 2.73
STEP 1599 EPOCH 2.73
STEP 1600 EPOCH 2.74
LOG loss=0.3494, grad_norm=1.8987860679626465, learning_rate=1.0555555555555555e-05, epoch=2.735042735042735
STEP 1601 EPOCH 2.74
STEP 1602 EPOCH 2.74
STEP 1603 EPOCH 2.74
STEP 1604 EPOCH 2.74
STEP 1605 EPOCH 2.74
STEP 1606 EPOCH 2.75
STEP 1607 EPOCH 2.75
STEP 1608 EPOCH 2.75
STEP 1609 EPOCH 2.75
STEP 1610 EPOCH 2.75
LOG loss=0.2683, grad_norm=0.363779217004776, learning_rate=1.0413105413105414e-05, epoch=2.752136752136752
STEP 1611 EPOCH 2.75
STEP 1612 EPOCH 2.76
STEP 1613 EPOCH 2.76
STEP 1614 EPOCH 2.76
STEP 1615 EPOCH 2.76
STEP 1616 EPOCH 2.76
STEP 1617 EPOCH 2.76
STEP 1618 EPOCH 2.77
STEP 1619 EPOCH 2.77
STEP 1620 EPOCH 2.77
LOG loss=0.1045, grad_norm=10.560047149658203, learning_rate=1.0270655270655272e-05, epoch=2.769230769230769
STEP 1621 EPOCH 2.77
STEP 1622 EPOCH 2.77
STEP 1623 EPOCH 2.77
STEP 1624 EPOCH 2.78
STEP 1625 EPOCH 2.78
STEP 1626 EPOCH 2.78
STEP 1627 EPOCH 2.78
STEP 1628 EPOCH 2.78
STEP 1629 EPOCH 2.78
STEP 1630 EPOCH 2.79
LOG loss=0.1277, grad_norm=0.01056670118123293, learning_rate=1.012820512820513e-05, epoch=2.786324786324786
STEP 1631 EPOCH 2.79
STEP 1632 EPOCH 2.79
STEP 1633 EPOCH 2.79
STEP 1634 EPOCH 2.79
STEP 1635 EPOCH 2.79
STEP 1636 EPOCH 2.80
STEP 1637 EPOCH 2.80
STEP 1638 EPOCH 2.80
STEP 1639 EPOCH 2.80
STEP 1640 EPOCH 2.80
LOG loss=0.2794, grad_norm=0.04856988787651062, learning_rate=9.985754985754987e-06, epoch=2.8034188034188032
STEP 1641 EPOCH 2.81
STEP 1642 EPOCH 2.81
STEP 1643 EPOCH 2.81
STEP 1644 EPOCH 2.81
STEP 1645 EPOCH 2.81
STEP 1646 EPOCH 2.81
STEP 1647 EPOCH 2.82
STEP 1648 EPOCH 2.82
STEP 1649 EPOCH 2.82
STEP 1650 EPOCH 2.82
LOG loss=0.1151, grad_norm=87.08332061767578, learning_rate=9.843304843304842e-06, epoch=2.8205128205128203
STEP 1651 EPOCH 2.82
STEP 1652 EPOCH 2.82
STEP 1653 EPOCH 2.83
STEP 1654 EPOCH 2.83
STEP 1655 EPOCH 2.83
STEP 1656 EPOCH 2.83
STEP 1657 EPOCH 2.83
STEP 1658 EPOCH 2.83
STEP 1659 EPOCH 2.84
STEP 1660 EPOCH 2.84
LOG loss=0.1283, grad_norm=5.00670051574707, learning_rate=9.700854700854701e-06, epoch=2.8376068376068377
STEP 1661 EPOCH 2.84
STEP 1662 EPOCH 2.84
STEP 1663 EPOCH 2.84
STEP 1664 EPOCH 2.84
STEP 1665 EPOCH 2.85
STEP 1666 EPOCH 2.85
STEP 1667 EPOCH 2.85
STEP 1668 EPOCH 2.85
STEP 1669 EPOCH 2.85
STEP 1670 EPOCH 2.85
LOG loss=0.2347, grad_norm=43.953880310058594, learning_rate=9.558404558404559e-06, epoch=2.8547008547008548
STEP 1671 EPOCH 2.86
STEP 1672 EPOCH 2.86
STEP 1673 EPOCH 2.86
STEP 1674 EPOCH 2.86
STEP 1675 EPOCH 2.86
STEP 1676 EPOCH 2.86
STEP 1677 EPOCH 2.87
STEP 1678 EPOCH 2.87
STEP 1679 EPOCH 2.87
STEP 1680 EPOCH 2.87
LOG loss=0.3319, grad_norm=57.16487503051758, learning_rate=9.415954415954416e-06, epoch=2.871794871794872
STEP 1681 EPOCH 2.87
STEP 1682 EPOCH 2.88
STEP 1683 EPOCH 2.88
STEP 1684 EPOCH 2.88
STEP 1685 EPOCH 2.88
STEP 1686 EPOCH 2.88
STEP 1687 EPOCH 2.88
STEP 1688 EPOCH 2.89
STEP 1689 EPOCH 2.89
STEP 1690 EPOCH 2.89
LOG loss=0.2688, grad_norm=1.2229918241500854, learning_rate=9.273504273504273e-06, epoch=2.888888888888889
STEP 1691 EPOCH 2.89
STEP 1692 EPOCH 2.89
STEP 1693 EPOCH 2.89
STEP 1694 EPOCH 2.90
STEP 1695 EPOCH 2.90
STEP 1696 EPOCH 2.90
STEP 1697 EPOCH 2.90
STEP 1698 EPOCH 2.90
STEP 1699 EPOCH 2.90
STEP 1700 EPOCH 2.91
LOG loss=0.1491, grad_norm=0.15541982650756836, learning_rate=9.13105413105413e-06, epoch=2.905982905982906
STEP 1701 EPOCH 2.91
STEP 1702 EPOCH 2.91
STEP 1703 EPOCH 2.91
STEP 1704 EPOCH 2.91
STEP 1705 EPOCH 2.91
STEP 1706 EPOCH 2.92
STEP 1707 EPOCH 2.92
STEP 1708 EPOCH 2.92
STEP 1709 EPOCH 2.92
STEP 1710 EPOCH 2.92
LOG loss=0.3481, grad_norm=0.11450797319412231, learning_rate=8.988603988603988e-06, epoch=2.9230769230769234
STEP 1711 EPOCH 2.92
STEP 1712 EPOCH 2.93
STEP 1713 EPOCH 2.93
STEP 1714 EPOCH 2.93
STEP 1715 EPOCH 2.93
STEP 1716 EPOCH 2.93
STEP 1717 EPOCH 2.94
STEP 1718 EPOCH 2.94
STEP 1719 EPOCH 2.94
STEP 1720 EPOCH 2.94
LOG loss=0.1985, grad_norm=0.5111085176467896, learning_rate=8.846153846153847e-06, epoch=2.9401709401709404
STEP 1721 EPOCH 2.94
STEP 1722 EPOCH 2.94
STEP 1723 EPOCH 2.95
STEP 1724 EPOCH 2.95
STEP 1725 EPOCH 2.95
STEP 1726 EPOCH 2.95
STEP 1727 EPOCH 2.95
STEP 1728 EPOCH 2.95
STEP 1729 EPOCH 2.96
STEP 1730 EPOCH 2.96
LOG loss=0.1527, grad_norm=33.04138946533203, learning_rate=8.703703703703705e-06, epoch=2.9572649572649574
STEP 1731 EPOCH 2.96
STEP 1732 EPOCH 2.96
STEP 1733 EPOCH 2.96
STEP 1734 EPOCH 2.96
STEP 1735 EPOCH 2.97
STEP 1736 EPOCH 2.97
STEP 1737 EPOCH 2.97
STEP 1738 EPOCH 2.97
STEP 1739 EPOCH 2.97
STEP 1740 EPOCH 2.97
LOG loss=0.2656, grad_norm=56.55897903442383, learning_rate=8.561253561253562e-06, epoch=2.9743589743589745
STEP 1741 EPOCH 2.98
STEP 1742 EPOCH 2.98
STEP 1743 EPOCH 2.98
STEP 1744 EPOCH 2.98
STEP 1745 EPOCH 2.98
STEP 1746 EPOCH 2.98
STEP 1747 EPOCH 2.99
STEP 1748 EPOCH 2.99
STEP 1749 EPOCH 2.99
STEP 1750 EPOCH 2.99
LOG loss=0.349, grad_norm=9.658853530883789, learning_rate=8.41880341880342e-06, epoch=2.9914529914529915
STEP 1751 EPOCH 2.99
STEP 1752 EPOCH 2.99
STEP 1753 EPOCH 3.00
STEP 1754 EPOCH 3.00
STEP 1755 EPOCH 3.00
STEP 1756 EPOCH 3.00
STEP 1757 EPOCH 3.00
STEP 1758 EPOCH 3.01
STEP 1759 EPOCH 3.01
STEP 1760 EPOCH 3.01
LOG loss=0.5231, grad_norm=82.06861877441406, learning_rate=8.276353276353277e-06, epoch=3.0085470085470085
STEP 1761 EPOCH 3.01
STEP 1762 EPOCH 3.01
STEP 1763 EPOCH 3.01
STEP 1764 EPOCH 3.02
STEP 1765 EPOCH 3.02
STEP 1766 EPOCH 3.02
STEP 1767 EPOCH 3.02
STEP 1768 EPOCH 3.02
STEP 1769 EPOCH 3.02
STEP 1770 EPOCH 3.03
LOG loss=0.6469, grad_norm=69.83914184570312, learning_rate=8.133903133903134e-06, epoch=3.0256410256410255
STEP 1771 EPOCH 3.03
STEP 1772 EPOCH 3.03
STEP 1773 EPOCH 3.03
STEP 1774 EPOCH 3.03
STEP 1775 EPOCH 3.03
STEP 1776 EPOCH 3.04
STEP 1777 EPOCH 3.04
STEP 1778 EPOCH 3.04
STEP 1779 EPOCH 3.04
STEP 1780 EPOCH 3.04
LOG loss=0.5326, grad_norm=1.8645813465118408, learning_rate=7.991452991452991e-06, epoch=3.0427350427350426
STEP 1781 EPOCH 3.04
STEP 1782 EPOCH 3.05
STEP 1783 EPOCH 3.05
STEP 1784 EPOCH 3.05
STEP 1785 EPOCH 3.05
STEP 1786 EPOCH 3.05
STEP 1787 EPOCH 3.05
STEP 1788 EPOCH 3.06
STEP 1789 EPOCH 3.06
STEP 1790 EPOCH 3.06
LOG loss=0.2235, grad_norm=3.5417118072509766, learning_rate=7.849002849002849e-06, epoch=3.0598290598290596
STEP 1791 EPOCH 3.06
STEP 1792 EPOCH 3.06
STEP 1793 EPOCH 3.06
STEP 1794 EPOCH 3.07
STEP 1795 EPOCH 3.07
STEP 1796 EPOCH 3.07
STEP 1797 EPOCH 3.07
STEP 1798 EPOCH 3.07
STEP 1799 EPOCH 3.08
STEP 1800 EPOCH 3.08
LOG loss=0.2241, grad_norm=2.5647823810577393, learning_rate=7.706552706552706e-06, epoch=3.076923076923077
STEP 1801 EPOCH 3.08
STEP 1802 EPOCH 3.08
STEP 1803 EPOCH 3.08
STEP 1804 EPOCH 3.08
STEP 1805 EPOCH 3.09
STEP 1806 EPOCH 3.09
STEP 1807 EPOCH 3.09
STEP 1808 EPOCH 3.09
STEP 1809 EPOCH 3.09
STEP 1810 EPOCH 3.09
LOG loss=0.4675, grad_norm=3.1409497261047363, learning_rate=7.564102564102564e-06, epoch=3.094017094017094
STEP 1811 EPOCH 3.10
STEP 1812 EPOCH 3.10
STEP 1813 EPOCH 3.10
STEP 1814 EPOCH 3.10
STEP 1815 EPOCH 3.10
STEP 1816 EPOCH 3.10
STEP 1817 EPOCH 3.11
STEP 1818 EPOCH 3.11
STEP 1819 EPOCH 3.11
STEP 1820 EPOCH 3.11
LOG loss=0.2477, grad_norm=1.0524094104766846, learning_rate=7.421652421652422e-06, epoch=3.111111111111111
STEP 1821 EPOCH 3.11
STEP 1822 EPOCH 3.11
STEP 1823 EPOCH 3.12
STEP 1824 EPOCH 3.12
STEP 1825 EPOCH 3.12
STEP 1826 EPOCH 3.12
STEP 1827 EPOCH 3.12
STEP 1828 EPOCH 3.12
STEP 1829 EPOCH 3.13
STEP 1830 EPOCH 3.13
LOG loss=0.4691, grad_norm=14.734517097473145, learning_rate=7.279202279202279e-06, epoch=3.128205128205128
STEP 1831 EPOCH 3.13
STEP 1832 EPOCH 3.13
STEP 1833 EPOCH 3.13
STEP 1834 EPOCH 3.14
STEP 1835 EPOCH 3.14
STEP 1836 EPOCH 3.14
STEP 1837 EPOCH 3.14
STEP 1838 EPOCH 3.14
STEP 1839 EPOCH 3.14
STEP 1840 EPOCH 3.15
LOG loss=0.2555, grad_norm=2.938082456588745, learning_rate=7.136752136752137e-06, epoch=3.1452991452991452
STEP 1841 EPOCH 3.15
STEP 1842 EPOCH 3.15
STEP 1843 EPOCH 3.15
STEP 1844 EPOCH 3.15
STEP 1845 EPOCH 3.15
STEP 1846 EPOCH 3.16
STEP 1847 EPOCH 3.16
STEP 1848 EPOCH 3.16
STEP 1849 EPOCH 3.16
STEP 1850 EPOCH 3.16
LOG loss=0.4264, grad_norm=18.13792610168457, learning_rate=6.994301994301995e-06, epoch=3.1623931623931623
STEP 1851 EPOCH 3.16
STEP 1852 EPOCH 3.17
STEP 1853 EPOCH 3.17
STEP 1854 EPOCH 3.17
STEP 1855 EPOCH 3.17
STEP 1856 EPOCH 3.17
STEP 1857 EPOCH 3.17
STEP 1858 EPOCH 3.18
STEP 1859 EPOCH 3.18
STEP 1860 EPOCH 3.18
LOG loss=0.3744, grad_norm=12.71608829498291, learning_rate=6.851851851851852e-06, epoch=3.1794871794871793
STEP 1861 EPOCH 3.18
STEP 1862 EPOCH 3.18
STEP 1863 EPOCH 3.18
STEP 1864 EPOCH 3.19
STEP 1865 EPOCH 3.19
STEP 1866 EPOCH 3.19
STEP 1867 EPOCH 3.19
STEP 1868 EPOCH 3.19
STEP 1869 EPOCH 3.19
STEP 1870 EPOCH 3.20
LOG loss=0.3085, grad_norm=52.32546615600586, learning_rate=6.7094017094017094e-06, epoch=3.1965811965811968
STEP 1871 EPOCH 3.20
STEP 1872 EPOCH 3.20
STEP 1873 EPOCH 3.20
STEP 1874 EPOCH 3.20
STEP 1875 EPOCH 3.21
STEP 1876 EPOCH 3.21
STEP 1877 EPOCH 3.21
STEP 1878 EPOCH 3.21
STEP 1879 EPOCH 3.21
STEP 1880 EPOCH 3.21
LOG loss=0.3947, grad_norm=6.48179292678833, learning_rate=6.566951566951567e-06, epoch=3.213675213675214
STEP 1881 EPOCH 3.22
STEP 1882 EPOCH 3.22
STEP 1883 EPOCH 3.22
STEP 1884 EPOCH 3.22
STEP 1885 EPOCH 3.22
STEP 1886 EPOCH 3.22
STEP 1887 EPOCH 3.23
STEP 1888 EPOCH 3.23
STEP 1889 EPOCH 3.23
STEP 1890 EPOCH 3.23
LOG loss=0.7289, grad_norm=0.21542008221149445, learning_rate=6.424501424501425e-06, epoch=3.230769230769231
STEP 1891 EPOCH 3.23
STEP 1892 EPOCH 3.23
STEP 1893 EPOCH 3.24
STEP 1894 EPOCH 3.24
STEP 1895 EPOCH 3.24
STEP 1896 EPOCH 3.24
STEP 1897 EPOCH 3.24
STEP 1898 EPOCH 3.24
STEP 1899 EPOCH 3.25
STEP 1900 EPOCH 3.25
LOG loss=0.4964, grad_norm=14.051871299743652, learning_rate=6.282051282051282e-06, epoch=3.247863247863248
STEP 1901 EPOCH 3.25
STEP 1902 EPOCH 3.25
STEP 1903 EPOCH 3.25
STEP 1904 EPOCH 3.25
STEP 1905 EPOCH 3.26
STEP 1906 EPOCH 3.26
STEP 1907 EPOCH 3.26
STEP 1908 EPOCH 3.26
STEP 1909 EPOCH 3.26
STEP 1910 EPOCH 3.26
LOG loss=0.3088, grad_norm=87.67687225341797, learning_rate=6.13960113960114e-06, epoch=3.264957264957265
STEP 1911 EPOCH 3.27
STEP 1912 EPOCH 3.27
STEP 1913 EPOCH 3.27
STEP 1914 EPOCH 3.27
STEP 1915 EPOCH 3.27
STEP 1916 EPOCH 3.28
STEP 1917 EPOCH 3.28
STEP 1918 EPOCH 3.28
STEP 1919 EPOCH 3.28
STEP 1920 EPOCH 3.28
LOG loss=0.1997, grad_norm=18.84493637084961, learning_rate=5.997150997150997e-06, epoch=3.282051282051282
STEP 1921 EPOCH 3.28
STEP 1922 EPOCH 3.29
STEP 1923 EPOCH 3.29
STEP 1924 EPOCH 3.29
STEP 1925 EPOCH 3.29
STEP 1926 EPOCH 3.29
STEP 1927 EPOCH 3.29
STEP 1928 EPOCH 3.30
STEP 1929 EPOCH 3.30
STEP 1930 EPOCH 3.30
LOG loss=0.1838, grad_norm=0.015870779752731323, learning_rate=5.8547008547008545e-06, epoch=3.299145299145299
STEP 1931 EPOCH 3.30
STEP 1932 EPOCH 3.30
STEP 1933 EPOCH 3.30
STEP 1934 EPOCH 3.31
STEP 1935 EPOCH 3.31
STEP 1936 EPOCH 3.31
STEP 1937 EPOCH 3.31
STEP 1938 EPOCH 3.31
STEP 1939 EPOCH 3.31
STEP 1940 EPOCH 3.32
LOG loss=0.3871, grad_norm=125.67840576171875, learning_rate=5.712250712250712e-06, epoch=3.316239316239316
STEP 1941 EPOCH 3.32
STEP 1942 EPOCH 3.32
STEP 1943 EPOCH 3.32
STEP 1944 EPOCH 3.32
STEP 1945 EPOCH 3.32
STEP 1946 EPOCH 3.33
STEP 1947 EPOCH 3.33
STEP 1948 EPOCH 3.33
STEP 1949 EPOCH 3.33
STEP 1950 EPOCH 3.33
LOG loss=0.1921, grad_norm=1.6555784940719604, learning_rate=5.56980056980057e-06, epoch=3.3333333333333335
STEP 1951 EPOCH 3.34
STEP 1952 EPOCH 3.34
STEP 1953 EPOCH 3.34
STEP 1954 EPOCH 3.34
STEP 1955 EPOCH 3.34
STEP 1956 EPOCH 3.34
STEP 1957 EPOCH 3.35
STEP 1958 EPOCH 3.35
STEP 1959 EPOCH 3.35
STEP 1960 EPOCH 3.35
LOG loss=0.3925, grad_norm=19.787986755371094, learning_rate=5.4273504273504275e-06, epoch=3.3504273504273505
STEP 1961 EPOCH 3.35
STEP 1962 EPOCH 3.35
STEP 1963 EPOCH 3.36
STEP 1964 EPOCH 3.36
STEP 1965 EPOCH 3.36
STEP 1966 EPOCH 3.36
STEP 1967 EPOCH 3.36
STEP 1968 EPOCH 3.36
STEP 1969 EPOCH 3.37
STEP 1970 EPOCH 3.37
LOG loss=0.4153, grad_norm=18.528940200805664, learning_rate=5.284900284900286e-06, epoch=3.3675213675213675
STEP 1971 EPOCH 3.37
STEP 1972 EPOCH 3.37
STEP 1973 EPOCH 3.37
STEP 1974 EPOCH 3.37
STEP 1975 EPOCH 3.38
STEP 1976 EPOCH 3.38
STEP 1977 EPOCH 3.38
STEP 1978 EPOCH 3.38
STEP 1979 EPOCH 3.38
STEP 1980 EPOCH 3.38
LOG loss=0.3656, grad_norm=83.57743072509766, learning_rate=5.142450142450142e-06, epoch=3.3846153846153846
STEP 1981 EPOCH 3.39
STEP 1982 EPOCH 3.39
STEP 1983 EPOCH 3.39
STEP 1984 EPOCH 3.39
STEP 1985 EPOCH 3.39
STEP 1986 EPOCH 3.39
STEP 1987 EPOCH 3.40
STEP 1988 EPOCH 3.40
STEP 1989 EPOCH 3.40
STEP 1990 EPOCH 3.40
LOG loss=0.6553, grad_norm=43.66221618652344, learning_rate=4.9999999999999996e-06, epoch=3.4017094017094016
STEP 1991 EPOCH 3.40
STEP 1992 EPOCH 3.41
STEP 1993 EPOCH 3.41
STEP 1994 EPOCH 3.41
STEP 1995 EPOCH 3.41
STEP 1996 EPOCH 3.41
STEP 1997 EPOCH 3.41
STEP 1998 EPOCH 3.42
STEP 1999 EPOCH 3.42
STEP 2000 EPOCH 3.42
LOG loss=0.2218, grad_norm=73.09194946289062, learning_rate=4.857549857549858e-06, epoch=3.4188034188034186
STEP 2001 EPOCH 3.42
STEP 2002 EPOCH 3.42
STEP 2003 EPOCH 3.42
STEP 2004 EPOCH 3.43
STEP 2005 EPOCH 3.43
STEP 2006 EPOCH 3.43
STEP 2007 EPOCH 3.43
STEP 2008 EPOCH 3.43
STEP 2009 EPOCH 3.43
STEP 2010 EPOCH 3.44
LOG loss=0.5713, grad_norm=136.32763671875, learning_rate=4.715099715099715e-06, epoch=3.435897435897436
STEP 2011 EPOCH 3.44
STEP 2012 EPOCH 3.44
STEP 2013 EPOCH 3.44
STEP 2014 EPOCH 3.44
STEP 2015 EPOCH 3.44
STEP 2016 EPOCH 3.45
STEP 2017 EPOCH 3.45
STEP 2018 EPOCH 3.45
STEP 2019 EPOCH 3.45
STEP 2020 EPOCH 3.45
LOG loss=0.5905, grad_norm=40.003173828125, learning_rate=4.5726495726495725e-06, epoch=3.452991452991453
STEP 2021 EPOCH 3.45
STEP 2022 EPOCH 3.46
STEP 2023 EPOCH 3.46
STEP 2024 EPOCH 3.46
STEP 2025 EPOCH 3.46
STEP 2026 EPOCH 3.46
STEP 2027 EPOCH 3.46
STEP 2028 EPOCH 3.47
STEP 2029 EPOCH 3.47
STEP 2030 EPOCH 3.47
LOG loss=0.3664, grad_norm=59.95263671875, learning_rate=4.430199430199431e-06, epoch=3.47008547008547
STEP 2031 EPOCH 3.47
STEP 2032 EPOCH 3.47
STEP 2033 EPOCH 3.48
STEP 2034 EPOCH 3.48
STEP 2035 EPOCH 3.48
STEP 2036 EPOCH 3.48
STEP 2037 EPOCH 3.48
STEP 2038 EPOCH 3.48
STEP 2039 EPOCH 3.49
STEP 2040 EPOCH 3.49
LOG loss=0.3025, grad_norm=17.222888946533203, learning_rate=4.287749287749288e-06, epoch=3.4871794871794872
STEP 2041 EPOCH 3.49
STEP 2042 EPOCH 3.49
STEP 2043 EPOCH 3.49
STEP 2044 EPOCH 3.49
STEP 2045 EPOCH 3.50
STEP 2046 EPOCH 3.50
STEP 2047 EPOCH 3.50
STEP 2048 EPOCH 3.50
STEP 2049 EPOCH 3.50
STEP 2050 EPOCH 3.50
LOG loss=0.3353, grad_norm=22.68895721435547, learning_rate=4.1452991452991455e-06, epoch=3.5042735042735043
STEP 2051 EPOCH 3.51
STEP 2052 EPOCH 3.51
STEP 2053 EPOCH 3.51
STEP 2054 EPOCH 3.51
STEP 2055 EPOCH 3.51
STEP 2056 EPOCH 3.51
STEP 2057 EPOCH 3.52
STEP 2058 EPOCH 3.52
STEP 2059 EPOCH 3.52
STEP 2060 EPOCH 3.52
LOG loss=0.3149, grad_norm=73.82483673095703, learning_rate=4.002849002849003e-06, epoch=3.5213675213675213
STEP 2061 EPOCH 3.52
STEP 2062 EPOCH 3.52
STEP 2063 EPOCH 3.53
STEP 2064 EPOCH 3.53
STEP 2065 EPOCH 3.53
STEP 2066 EPOCH 3.53
STEP 2067 EPOCH 3.53
STEP 2068 EPOCH 3.54
STEP 2069 EPOCH 3.54
STEP 2070 EPOCH 3.54
LOG loss=0.2961, grad_norm=1.8768179416656494, learning_rate=3.86039886039886e-06, epoch=3.5384615384615383
STEP 2071 EPOCH 3.54
STEP 2072 EPOCH 3.54
STEP 2073 EPOCH 3.54
STEP 2074 EPOCH 3.55
STEP 2075 EPOCH 3.55
STEP 2076 EPOCH 3.55
STEP 2077 EPOCH 3.55
STEP 2078 EPOCH 3.55
STEP 2079 EPOCH 3.55
STEP 2080 EPOCH 3.56
LOG loss=0.1098, grad_norm=0.05518782138824463, learning_rate=3.717948717948718e-06, epoch=3.5555555555555554
STEP 2081 EPOCH 3.56
STEP 2082 EPOCH 3.56
STEP 2083 EPOCH 3.56
STEP 2084 EPOCH 3.56
STEP 2085 EPOCH 3.56
STEP 2086 EPOCH 3.57
STEP 2087 EPOCH 3.57
STEP 2088 EPOCH 3.57
STEP 2089 EPOCH 3.57
STEP 2090 EPOCH 3.57
LOG loss=0.1206, grad_norm=14.453676223754883, learning_rate=3.5754985754985754e-06, epoch=3.5726495726495724
STEP 2091 EPOCH 3.57
STEP 2092 EPOCH 3.58
STEP 2093 EPOCH 3.58
STEP 2094 EPOCH 3.58
STEP 2095 EPOCH 3.58
STEP 2096 EPOCH 3.58
STEP 2097 EPOCH 3.58
STEP 2098 EPOCH 3.59
STEP 2099 EPOCH 3.59
STEP 2100 EPOCH 3.59
LOG loss=0.209, grad_norm=0.04437608644366264, learning_rate=3.433048433048433e-06, epoch=3.58974358974359
STEP 2101 EPOCH 3.59
STEP 2102 EPOCH 3.59
STEP 2103 EPOCH 3.59
STEP 2104 EPOCH 3.60
STEP 2105 EPOCH 3.60
STEP 2106 EPOCH 3.60
STEP 2107 EPOCH 3.60
STEP 2108 EPOCH 3.60
STEP 2109 EPOCH 3.61
STEP 2110 EPOCH 3.61
LOG loss=0.2767, grad_norm=184.007080078125, learning_rate=3.290598290598291e-06, epoch=3.606837606837607
STEP 2111 EPOCH 3.61
STEP 2112 EPOCH 3.61
STEP 2113 EPOCH 3.61
STEP 2114 EPOCH 3.61
STEP 2115 EPOCH 3.62
STEP 2116 EPOCH 3.62
STEP 2117 EPOCH 3.62
STEP 2118 EPOCH 3.62
STEP 2119 EPOCH 3.62
STEP 2120 EPOCH 3.62
LOG loss=0.1933, grad_norm=12.7661714553833, learning_rate=3.148148148148148e-06, epoch=3.623931623931624
STEP 2121 EPOCH 3.63
STEP 2122 EPOCH 3.63
STEP 2123 EPOCH 3.63
STEP 2124 EPOCH 3.63
STEP 2125 EPOCH 3.63
STEP 2126 EPOCH 3.63
STEP 2127 EPOCH 3.64
STEP 2128 EPOCH 3.64
STEP 2129 EPOCH 3.64
STEP 2130 EPOCH 3.64
LOG loss=0.244, grad_norm=9.188700675964355, learning_rate=3.0056980056980057e-06, epoch=3.641025641025641
STEP 2131 EPOCH 3.64
STEP 2132 EPOCH 3.64
STEP 2133 EPOCH 3.65
STEP 2134 EPOCH 3.65
STEP 2135 EPOCH 3.65
STEP 2136 EPOCH 3.65
STEP 2137 EPOCH 3.65
STEP 2138 EPOCH 3.65
STEP 2139 EPOCH 3.66
STEP 2140 EPOCH 3.66
LOG loss=0.246, grad_norm=16.44583511352539, learning_rate=2.8632478632478635e-06, epoch=3.658119658119658
STEP 2141 EPOCH 3.66
STEP 2142 EPOCH 3.66
STEP 2143 EPOCH 3.66
STEP 2144 EPOCH 3.66
STEP 2145 EPOCH 3.67
STEP 2146 EPOCH 3.67
STEP 2147 EPOCH 3.67
STEP 2148 EPOCH 3.67
STEP 2149 EPOCH 3.67
STEP 2150 EPOCH 3.68
LOG loss=0.2133, grad_norm=29.69456672668457, learning_rate=2.720797720797721e-06, epoch=3.6752136752136755
STEP 2151 EPOCH 3.68
STEP 2152 EPOCH 3.68
STEP 2153 EPOCH 3.68
STEP 2154 EPOCH 3.68
STEP 2155 EPOCH 3.68
STEP 2156 EPOCH 3.69
STEP 2157 EPOCH 3.69
STEP 2158 EPOCH 3.69
STEP 2159 EPOCH 3.69
STEP 2160 EPOCH 3.69
LOG loss=0.1918, grad_norm=4.582422256469727, learning_rate=2.5783475783475782e-06, epoch=3.6923076923076925
STEP 2161 EPOCH 3.69
STEP 2162 EPOCH 3.70
STEP 2163 EPOCH 3.70
STEP 2164 EPOCH 3.70
STEP 2165 EPOCH 3.70
STEP 2166 EPOCH 3.70
STEP 2167 EPOCH 3.70
STEP 2168 EPOCH 3.71
STEP 2169 EPOCH 3.71
STEP 2170 EPOCH 3.71
LOG loss=0.3072, grad_norm=46.384639739990234, learning_rate=2.435897435897436e-06, epoch=3.7094017094017095
STEP 2171 EPOCH 3.71
STEP 2172 EPOCH 3.71
STEP 2173 EPOCH 3.71
STEP 2174 EPOCH 3.72
STEP 2175 EPOCH 3.72
STEP 2176 EPOCH 3.72
STEP 2177 EPOCH 3.72
STEP 2178 EPOCH 3.72
STEP 2179 EPOCH 3.72
STEP 2180 EPOCH 3.73
LOG loss=0.2521, grad_norm=9.312832832336426, learning_rate=2.2934472934472934e-06, epoch=3.7264957264957266
STEP 2181 EPOCH 3.73
STEP 2182 EPOCH 3.73
STEP 2183 EPOCH 3.73
STEP 2184 EPOCH 3.73
STEP 2185 EPOCH 3.74
STEP 2186 EPOCH 3.74
STEP 2187 EPOCH 3.74
STEP 2188 EPOCH 3.74
STEP 2189 EPOCH 3.74
STEP 2190 EPOCH 3.74
LOG loss=0.2091, grad_norm=0.05157168582081795, learning_rate=2.150997150997151e-06, epoch=3.7435897435897436
STEP 2191 EPOCH 3.75
STEP 2192 EPOCH 3.75
STEP 2193 EPOCH 3.75
STEP 2194 EPOCH 3.75
STEP 2195 EPOCH 3.75
STEP 2196 EPOCH 3.75
STEP 2197 EPOCH 3.76
STEP 2198 EPOCH 3.76
STEP 2199 EPOCH 3.76
STEP 2200 EPOCH 3.76
LOG loss=0.4021, grad_norm=41.828285217285156, learning_rate=2.0085470085470086e-06, epoch=3.7606837606837606
STEP 2201 EPOCH 3.76
STEP 2202 EPOCH 3.76
STEP 2203 EPOCH 3.77
STEP 2204 EPOCH 3.77
STEP 2205 EPOCH 3.77
STEP 2206 EPOCH 3.77
STEP 2207 EPOCH 3.77
STEP 2208 EPOCH 3.77
STEP 2209 EPOCH 3.78
STEP 2210 EPOCH 3.78
LOG loss=0.5157, grad_norm=44.93465805053711, learning_rate=1.8660968660968661e-06, epoch=3.7777777777777777
STEP 2211 EPOCH 3.78
STEP 2212 EPOCH 3.78
STEP 2213 EPOCH 3.78
STEP 2214 EPOCH 3.78
STEP 2215 EPOCH 3.79
STEP 2216 EPOCH 3.79
STEP 2217 EPOCH 3.79
STEP 2218 EPOCH 3.79
STEP 2219 EPOCH 3.79
STEP 2220 EPOCH 3.79
LOG loss=0.3167, grad_norm=1.4416604042053223, learning_rate=1.7236467236467237e-06, epoch=3.7948717948717947
STEP 2221 EPOCH 3.80
STEP 2222 EPOCH 3.80
STEP 2223 EPOCH 3.80
STEP 2224 EPOCH 3.80
STEP 2225 EPOCH 3.80
STEP 2226 EPOCH 3.81
STEP 2227 EPOCH 3.81
STEP 2228 EPOCH 3.81
STEP 2229 EPOCH 3.81
STEP 2230 EPOCH 3.81
LOG loss=0.3947, grad_norm=40.323753356933594, learning_rate=1.5811965811965813e-06, epoch=3.8119658119658117
STEP 2231 EPOCH 3.81
STEP 2232 EPOCH 3.82
STEP 2233 EPOCH 3.82
STEP 2234 EPOCH 3.82
STEP 2235 EPOCH 3.82
STEP 2236 EPOCH 3.82
STEP 2237 EPOCH 3.82
STEP 2238 EPOCH 3.83
STEP 2239 EPOCH 3.83
STEP 2240 EPOCH 3.83
LOG loss=0.5139, grad_norm=38.90805435180664, learning_rate=1.4387464387464389e-06, epoch=3.8290598290598292
STEP 2241 EPOCH 3.83
STEP 2242 EPOCH 3.83
STEP 2243 EPOCH 3.83
STEP 2244 EPOCH 3.84
STEP 2245 EPOCH 3.84
STEP 2246 EPOCH 3.84
STEP 2247 EPOCH 3.84
STEP 2248 EPOCH 3.84
STEP 2249 EPOCH 3.84
STEP 2250 EPOCH 3.85
LOG loss=0.3424, grad_norm=30.604318618774414, learning_rate=1.2962962962962962e-06, epoch=3.8461538461538463
STEP 2251 EPOCH 3.85
STEP 2252 EPOCH 3.85
STEP 2253 EPOCH 3.85
STEP 2254 EPOCH 3.85
STEP 2255 EPOCH 3.85
STEP 2256 EPOCH 3.86
STEP 2257 EPOCH 3.86
STEP 2258 EPOCH 3.86
STEP 2259 EPOCH 3.86
STEP 2260 EPOCH 3.86
LOG loss=0.3292, grad_norm=24.882617950439453, learning_rate=1.153846153846154e-06, epoch=3.8632478632478633
STEP 2261 EPOCH 3.86
STEP 2262 EPOCH 3.87
STEP 2263 EPOCH 3.87
STEP 2264 EPOCH 3.87
STEP 2265 EPOCH 3.87
STEP 2266 EPOCH 3.87
STEP 2267 EPOCH 3.88
STEP 2268 EPOCH 3.88
STEP 2269 EPOCH 3.88
STEP 2270 EPOCH 3.88
LOG loss=0.3683, grad_norm=70.61404418945312, learning_rate=1.0113960113960114e-06, epoch=3.8803418803418803
STEP 2271 EPOCH 3.88
STEP 2272 EPOCH 3.88
STEP 2273 EPOCH 3.89
STEP 2274 EPOCH 3.89
STEP 2275 EPOCH 3.89
STEP 2276 EPOCH 3.89
STEP 2277 EPOCH 3.89
STEP 2278 EPOCH 3.89
STEP 2279 EPOCH 3.90
STEP 2280 EPOCH 3.90
LOG loss=0.2266, grad_norm=85.21690368652344, learning_rate=8.68945868945869e-07, epoch=3.8974358974358974
STEP 2281 EPOCH 3.90
STEP 2282 EPOCH 3.90
STEP 2283 EPOCH 3.90
STEP 2284 EPOCH 3.90
STEP 2285 EPOCH 3.91
STEP 2286 EPOCH 3.91
STEP 2287 EPOCH 3.91
STEP 2288 EPOCH 3.91
STEP 2289 EPOCH 3.91
STEP 2290 EPOCH 3.91
LOG loss=0.1238, grad_norm=14.023776054382324, learning_rate=7.264957264957265e-07, epoch=3.9145299145299144
STEP 2291 EPOCH 3.92
STEP 2292 EPOCH 3.92
STEP 2293 EPOCH 3.92
STEP 2294 EPOCH 3.92
STEP 2295 EPOCH 3.92
STEP 2296 EPOCH 3.92
STEP 2297 EPOCH 3.93
STEP 2298 EPOCH 3.93
STEP 2299 EPOCH 3.93
STEP 2300 EPOCH 3.93
LOG loss=0.4019, grad_norm=28.83193588256836, learning_rate=5.84045584045584e-07, epoch=3.931623931623932
STEP 2301 EPOCH 3.93
STEP 2302 EPOCH 3.94
STEP 2303 EPOCH 3.94
STEP 2304 EPOCH 3.94
STEP 2305 EPOCH 3.94
STEP 2306 EPOCH 3.94
STEP 2307 EPOCH 3.94
STEP 2308 EPOCH 3.95
STEP 2309 EPOCH 3.95
STEP 2310 EPOCH 3.95
LOG loss=0.3092, grad_norm=7.098494529724121, learning_rate=4.415954415954416e-07, epoch=3.948717948717949
STEP 2311 EPOCH 3.95
STEP 2312 EPOCH 3.95
STEP 2313 EPOCH 3.95
STEP 2314 EPOCH 3.96
STEP 2315 EPOCH 3.96
STEP 2316 EPOCH 3.96
STEP 2317 EPOCH 3.96
STEP 2318 EPOCH 3.96
STEP 2319 EPOCH 3.96
STEP 2320 EPOCH 3.97
LOG loss=0.2028, grad_norm=31.014326095581055, learning_rate=2.9914529914529915e-07, epoch=3.965811965811966
STEP 2321 EPOCH 3.97
STEP 2322 EPOCH 3.97
STEP 2323 EPOCH 3.97
STEP 2324 EPOCH 3.97
STEP 2325 EPOCH 3.97
STEP 2326 EPOCH 3.98
STEP 2327 EPOCH 3.98
STEP 2328 EPOCH 3.98
STEP 2329 EPOCH 3.98
STEP 2330 EPOCH 3.98
LOG loss=0.2133, grad_norm=8.82419490814209, learning_rate=1.566951566951567e-07, epoch=3.982905982905983
STEP 2331 EPOCH 3.98
STEP 2332 EPOCH 3.99
STEP 2333 EPOCH 3.99
STEP 2334 EPOCH 3.99
STEP 2335 EPOCH 3.99
STEP 2336 EPOCH 3.99
STEP 2337 EPOCH 3.99
STEP 2338 EPOCH 4.00
STEP 2339 EPOCH 4.00
STEP 2340 EPOCH 4.00
LOG loss=0.2289, grad_norm=0.0027553837280720472, learning_rate=1.4245014245014247e-08, epoch=4.0
LOG train_runtime=656.0667, train_samples_per_second=28.491, train_steps_per_second=3.567, total_flos=184822978913280.0, train_loss=0.1954473216038866, epoch=4.0
TRAINING_FINISHED 2025-08-14 14:07:57
LOG eval_loss=1.9113502502441406, eval_accuracy=0.7174657534246576, eval_f1_macro=0.648248756317794, eval_runtime=4.3157, eval_samples_per_second=135.321, eval_steps_per_second=16.915, epoch=4.0
LOG eval_loss=1.6607452630996704, eval_accuracy=0.7606837606837606, eval_f1_macro=0.691351063124479, eval_runtime=4.4804, eval_samples_per_second=130.569, eval_steps_per_second=16.516, epoch=4.0
